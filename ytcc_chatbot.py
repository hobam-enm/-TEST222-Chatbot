
# region [Imports & Setup]
import streamlit as st
from io import BytesIO
from functools import lru_cache

# PDF export (lazy import inside functions)
import pandas as pd
import os
import re
import gc
import time
import json
import base64
import requests
from datetime import datetime, timedelta, timezone
from concurrent.futures import ThreadPoolExecutor, as_completed
from uuid import uuid4
import io
import threading

from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
import google.generativeai as genai
from google.generativeai import caching  # [ì¶”ê°€] ìºì‹± ëª¨ë“ˆ
from streamlit.components.v1 import html as st_html

# ê²½ë¡œ ë° GitHub ì„¤ì •
BASE_DIR = "/tmp"
SESS_DIR = os.path.join(BASE_DIR, "sessions")
os.makedirs(SESS_DIR, exist_ok=True)

GITHUB_TOKEN = st.secrets.get("GITHUB_TOKEN", "")
GITHUB_REPO = st.secrets.get("GITHUB_REPO", "")
GITHUB_BRANCH = st.secrets.get("GITHUB_BRANCH", "main")


# (ì¶”ê°€) 1ì°¨ ë¶„ì„ í”„ë¡¬í”„íŠ¸ íŒŒì¼ (ë ˆí¬ì— í•¨ê»˜ ì»¤ë°‹í•´ë‘ë©´ ìë™ ì ìš©)
FIRST_TURN_PROMPT_FILE = "1ì°¨ ì§ˆë¬¸ í”„ë¡¬í”„íŠ¸.md"
REPO_DIR = os.path.dirname(os.path.abspath(__file__))
PGC_CACHE_DIR = os.path.join(REPO_DIR, "pgc_cache")

def load_first_turn_system_prompt() -> str:
    """ë ˆí¬ì˜ '1ì°¨ ì§ˆë¬¸ í”„ë¡¬í”„íŠ¸.md'ë§Œ ì‚¬ìš©í•œë‹¤(í´ë°± ì—†ìŒ)."""
    if not os.path.exists(FIRST_TURN_PROMPT_FILE):
        raise RuntimeError(f"í”„ë¡¬í”„íŠ¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {FIRST_TURN_PROMPT_FILE}")
    with open(FIRST_TURN_PROMPT_FILE, "r", encoding="utf-8") as f:
        txt = f.read().strip()
    if not txt:
        raise RuntimeError(f"í”„ë¡¬í”„íŠ¸ íŒŒì¼ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤: {FIRST_TURN_PROMPT_FILE}")
    return txt


KST = timezone(timedelta(hours=9))

def now_kst() -> datetime:
    return datetime.now(tz=KST)

def to_iso_kst(dt: datetime) -> str:
    if dt.tzinfo is None:
        dt = dt.replace(tzinfo=KST)
    return dt.astimezone(KST).isoformat(timespec="seconds")

def kst_to_rfc3339_utc(dt_kst: datetime) -> str:
    if dt_kst.tzinfo is None:
        dt_kst = dt_kst.replace(tzinfo=KST)
    return dt_kst.astimezone(timezone.utc).isoformat().replace("+00:00", "Z")
# endregion



# region [Page Config & CSS]
st.set_page_config(
    page_title="(í…ŒìŠ¤íŠ¸)ìœ íŠœë¸Œ ëŒ“ê¸€ë¶„ì„: ì±—ë´‡",
    layout="wide",
    initial_sidebar_state="expanded"
)

GLOBAL_CSS = r'''
<style>
  /* ===== App chrome ===== */
  header, footer, #MainMenu { visibility: hidden; }

  /* ===== Main padding ===== */
  .main .block-container{
    padding-top: 1.6rem;
    padding-right: 1rem;
    padding-left: 1rem;
    padding-bottom: 5rem;
    max-width: 1300px;
  }

  /* ===== Sidebar width ===== */
  [data-testid="stSidebar"]{
    width: 360px !important;
    min-width: 360px !important;
    max-width: 360px !important;
  }
  [data-testid="stSidebar"] + div[class*="resizer"]{ display:none; }

  /* ===== Sidebar base spacing reset ===== */
  [data-testid="stSidebarContent"]{
    padding: 12px 14px 12px 14px !important;
  }
  [data-testid="stSidebar"] .element-container,
  [data-testid="stSidebar"] .stMarkdown,
  [data-testid="stSidebar"] .stButton,
  [data-testid="stSidebar"] .stDownloadButton,
  [data-testid="stSidebar"] [data-testid="stVerticalBlock"] > div{
    margin: 0 !important;
    padding: 0 !important;
  }
  [data-testid="stSidebar"] [data-testid="stHorizontalBlock"]{
    gap: 8px !important;
    margin: 0 !important;
    padding: 0 !important;
  }

  /* Divider / section title spacing */
  [data-testid="stSidebar"] hr{
    margin: 10px 0 !important;
  }
  [data-testid="stSidebar"] h4,
  [data-testid="stSidebar"] .stMarkdown h4{
    margin: 8px 0 8px 0 !important;
    padding: 0 !important;
    font-weight: 700;
  }

  /* ===== Session list (ëŒ€í™” ê¸°ë¡) ===== */
  .session-list{
    margin-top: 6px !important;
  }
  .session-list .sess-name .stButton button{
    background: #ffffff !important;
    border: 1px solid #e5e7eb !important;
    border-radius: 14px !important;
    padding: 0.52rem 0.72rem !important;
    box-shadow: none !important;
    color: #111827 !important;
    font-size: 0.90rem !important;
    font-weight: 650 !important;
    text-align: left !important;
    width: 100% !important;
    overflow: hidden !important;
    text-overflow: ellipsis !important;
    white-space: nowrap !important;
  }
  .session-list .sess-name .stButton button:hover{
    border-color: #d1d5db !important;
    background: #f9fafb !important;
  }

  /* â‹¯ ë²„íŠ¼ */
  .session-list .more-menu .stButton button{
    background: #ffffff !important;
    border: 1px solid #e5e7eb !important;
    border-radius: 12px !important;
    padding: 0.48rem 0.55rem !important;
    min-height: 2.15rem !important;
    line-height: 1 !important;
    box-shadow: none !important;
  }
  .session-list .more-menu .stButton button:hover{
    border-color: #d1d5db !important;
    background: #f9fafb !important;
  }

  /* Rename input compact */
  [data-testid="stSidebar"] input{
    padding-top: 0.38rem !important;
    padding-bottom: 0.38rem !important;
  }

  /* Assistant message font */
  [data-testid="stChatMessage"]:has(span[data-testid="chat-avatar-assistant"]) p,
  [data-testid="stChatMessage"]:has(span[data-testid="chat-avatar-assistant"]) li{
    font-size: 0.95rem;
  }
</style>
'''
st.markdown(GLOBAL_CSS, unsafe_allow_html=True)
# endregion


# region [Constants & State Management]
_YT_FALLBACK, _GEM_FALLBACK = [], []
YT_API_KEYS       = list(st.secrets.get("YT_API_KEYS", [])) or _YT_FALLBACK
GEMINI_API_KEYS   = list(st.secrets.get("GEMINI_API_KEYS", [])) or _GEM_FALLBACK
GEMINI_MODEL      = "gemini-3-flash-preview"  
GEMINI_TIMEOUT    = 120
GEMINI_MAX_TOKENS = 8192
MAX_TOTAL_COMMENTS   = 120_000
MAX_COMMENTS_PER_VID = 4_000
CACHE_TTL_MINUTES    = 20  # [ì¶”ê°€] ìºì‹œ ìˆ˜ëª… (ë¶„)

# [ì¶”ê°€] Gemini ë™ì‹œ í˜¸ì¶œ(In-flight) ì œí•œ
MAX_GEMINI_INFLIGHT = max(1, int(st.secrets.get("MAX_GEMINI_INFLIGHT", 3) or 3))
GEMINI_INFLIGHT_WAIT_SEC = int(st.secrets.get("GEMINI_INFLIGHT_WAIT_SEC", 120) or 120)

# í”„ë¡œì„¸ìŠ¤ ì „ì—­ ì„¸ë§ˆí¬ì–´ (ë™ì‹œ Gemini í˜¸ì¶œ ì œí•œ)
_GEMINI_SEM = threading.BoundedSemaphore(MAX_GEMINI_INFLIGHT)
_GEMINI_TLOCAL = threading.local()

class GeminiInflightSlot:
    """Gemini API í˜¸ì¶œ ë™ì‹œì„± ì œí•œ.

    - ë™ì¼ ìŠ¤ë ˆë“œì—ì„œ ì¤‘ì²© í˜¸ì¶œ(ìºì‹œ -> í´ë°± ë“±) ì‹œ ë°ë“œë½ ë°©ì§€.
    - ìŠ¬ë¡¯ì´ ì—†ìœ¼ë©´ ìµœëŒ€ GEMINI_INFLIGHT_WAIT_SEC ë™ì•ˆ ëŒ€ê¸°.
    """
    def __init__(self, wait_sec: int = None):
        self.wait_sec = GEMINI_INFLIGHT_WAIT_SEC if wait_sec is None else int(wait_sec)
        self.acquired = False

    def __enter__(self):
        if getattr(_GEMINI_TLOCAL, "held", False):
            # ì¬ì§„ì…: ì´ë¯¸ ìŠ¬ë¡¯ ë³´ìœ  (ì¤‘ì²© í˜¸ì¶œ ë°ë“œë½ ë°©ì§€)
            return self

        deadline = time.time() + max(0, self.wait_sec)
        while True:
            if _GEMINI_SEM.acquire(timeout=0.2):
                self.acquired = True
                _GEMINI_TLOCAL.held = True
                return self
            if time.time() >= deadline:
                raise TimeoutError("GEMINI_INFLIGHT_TIMEOUT")

    def __exit__(self, exc_type, exc, tb):
        if self.acquired:
            _GEMINI_TLOCAL.held = False
            _GEMINI_SEM.release()
        return False


def ensure_state():
    defaults = {
        "chat": [],
        "last_schema": None,
        "last_csv": "",
        "last_df": None,
        "sample_text": "",
        "loaded_session_name": None,
        "own_ip_mode": False,
        "own_ip_toggle_prev": None,
        "current_cache": None, # [ì¶”ê°€] ìºì‹œ ì •ë³´ ì €ì¥ìš©
    }
    for k, v in defaults.items():
        if k not in st.session_state:
            st.session_state[k] = v


def _reset_chat_only(keep_auth: bool = True):
    """ì „ì²´ clear() ëŒ€ì‹ , ëŒ€í™”/ë¶„ì„ ìƒíƒœë§Œ ì•ˆì „í•˜ê²Œ ì´ˆê¸°í™”."""
    auth_keys = {
        "auth_ok", "auth_user_id", "auth_role", "auth_display_name",
        "client_instance_id", "_auth_users_cache"
    }
    # íë¦„ ì œì–´ í‚¤ê°€ ìˆë‹¤ë©´ ì—¬ê¸° ìœ ì§€(ì•± ë‚´ì—ì„œ ì‚¬ìš© ì¤‘ì´ë©´)
    safe_flow_keys = {"session_to_load", "session_to_delete"}
    keep = set()
    if keep_auth:
        keep |= auth_keys
    keep |= safe_flow_keys

    for k in list(st.session_state.keys()):
        if k in keep:
            continue
        del st.session_state[k]

    ensure_state()

ensure_state()
# endregion


# region [PDF Export: current session -> PDF]
@lru_cache(maxsize=1)
def _pdf_font_name() -> str:
    """Return a registered font name for Korean text if available. Fallback: Helvetica."""
    try:
        from reportlab.pdfbase import pdfmetrics
        from reportlab.pdfbase.ttfonts import TTFont
    except ModuleNotFoundError:
        return "Helvetica"

    candidates = [
        ("NanumGothic", "./fonts/NanumGothic.ttf"),
        ("NanumGothic", "./NanumGothic.ttf"),
        ("NanumGothic", "/usr/share/fonts/truetype/nanum/NanumGothic.ttf"),
        ("NanumGothicCoding", "/usr/share/fonts/truetype/nanum/NanumGothicCoding.ttf"),
        ("UnDotum", "/usr/share/fonts/truetype/unfonts-core/UnDotum.ttf"),
        ("UnBatang", "/usr/share/fonts/truetype/unfonts-core/UnBatang.ttf"),
        ("NotoSansCJKkr", "/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc"),
        ("NotoSansKR", "/usr/share/fonts/truetype/noto/NotoSansKR-Regular.ttf"),
    ]

    for name, fp in candidates:
        if os.path.exists(fp):
            try:
                # Avoid duplicate registration errors
                if name not in pdfmetrics.getRegisteredFontNames():
                    pdfmetrics.registerFont(TTFont(name, fp))
                return name
            except Exception:
                continue
    return "Helvetica"


def _strip_html_to_text(s: str) -> str:
    """Best-effort: convert HTML-ish strings to readable text for PDF."""
    if not s:
        return ""
    # Common line breaks
    s = re.sub(r"<\s*br\s*/?\s*>", "\n", s, flags=re.I)
    s = re.sub(r"</\s*p\s*>", "\n\n", s, flags=re.I)
    s = re.sub(r"<\s*li\s*>", "â€¢ ", s, flags=re.I)
    s = re.sub(r"</\s*li\s*>", "\n", s, flags=re.I)
    # Remove all tags
    s = re.sub(r"<[^>]+>", "", s)
    # Unescape entities
    try:
        import html as _html
        s = _html.unescape(s)
    except Exception:
        pass
    # Normalize whitespace
    s = s.replace("\r\n", "\n").replace("\r", "\n")
    s = re.sub(r"\n{3,}", "\n\n", s).strip()
    return s


def build_session_pdf_bytes(session_title: str, user_label: str, chat: list) -> bytes:
    """
    Export the current session as a 'captured-like' chat PDF:
    - user/assistant speech bubbles
    - left/right alignment
    - HTML tags stripped (so raw HTML won't leak into PDF)
    """
    try:
        from reportlab.lib.pagesizes import A4
        from reportlab.pdfgen import canvas
        from reportlab.lib.utils import simpleSplit
        from reportlab.lib.colors import HexColor
    except ModuleNotFoundError:
        return b""  # reportlab missing

    font = _pdf_font_name()

    buf = BytesIO()
    c = canvas.Canvas(buf, pagesize=A4)
    w, h = A4

    # Layout
    margin_l, margin_r = 18 * 2.8346, 18 * 2.8346  # ~18mm
    margin_t, margin_b = 18 * 2.8346, 18 * 2.8346
    max_bubble_w = (w - margin_l - margin_r) * 0.78
    pad_x, pad_y = 10, 8
    line_h = 13

    y = h - margin_t

    def new_page():
        nonlocal y
        c.showPage()
        y = h - margin_t

    def draw_title():
        nonlocal y
        c.setFont(font, 16)
        c.drawString(margin_l, y, f"ëŒ€í™” ê¸°ë¡: {session_title}")
        y -= 22
        c.setFont(font, 10)
        ts = datetime.now().strftime("%Y-%m-%d %H:%M")
        label = (user_label or "").strip()
        c.drawString(margin_l, y, f"ì‚¬ìš©ì: {label}   Â·   ìƒì„±: {ts}")
        y -= 18
        y -= 8

    def draw_bubble(role: str, text: str):
        nonlocal y
        role = (role or "").lower()
        is_user = role == "user"

        # Colors
        fill = HexColor("#EAFBF2") if is_user else HexColor("#F3F4F6")
        stroke = HexColor("#CDEEDB") if is_user else HexColor("#E5E7EB")
        text_color = HexColor("#0F172A")

        # Clean text
        t = _strip_html_to_text(text or "")
        if not t:
            t = " "

        # Split lines by paragraphs then wrap
        c.setFont(font, 10.5)
        wrapped = []
        for para in t.split("\n"):
            if para.strip() == "":
                wrapped.append("")
                continue
            wrapped.extend(simpleSplit(para, font, 10.5, max_bubble_w - pad_x * 2))
        if not wrapped:
            wrapped = [" "]

        bubble_h = pad_y * 2 + line_h * len(wrapped) + 10  # +label space
        # Page break if needed
        if y - bubble_h < margin_b:
            new_page()

        # Bubble width: fit to longest line (capped)
        max_line_w = 0
        for ln in wrapped:
            try:
                max_line_w = max(max_line_w, c.stringWidth(ln, font, 10.5))
            except Exception:
                pass
        bubble_w = min(max_bubble_w, max(220, max_line_w + pad_x * 2))  # minimum width

        x = (w - margin_r - bubble_w) if is_user else margin_l

        # Draw label
        c.setFillColor(HexColor("#64748B"))
        c.setFont(font, 9)
        who = "ë‚˜" if is_user else "AI"
        c.drawString(x + pad_x, y, who)
        y -= 12

        # Bubble rect
        c.setFillColor(fill)
        c.setStrokeColor(stroke)
        c.roundRect(x, y - (bubble_h - 12), bubble_w, bubble_h - 12, 10, fill=1, stroke=1)

        # Text
        c.setFillColor(text_color)
        c.setFont(font, 10.5)
        tx = x + pad_x
        ty = y - pad_y - 2
        for ln in wrapped:
            c.drawString(tx, ty, ln)
            ty -= line_h

        # Advance y
        y = y - (bubble_h - 12) - 12

    draw_title()

    for m in chat or []:
        draw_bubble(m.get("role"), m.get("content", ""))

    c.save()
    return buf.getvalue()


def _session_title_for_pdf() -> str:

    return st.session_state.get("loaded_session_name") or "í˜„ì¬ëŒ€í™”"

def _get_cached_session_pdf_bytes() -> bytes:
    title = _session_title_for_pdf()
    user_label = st.session_state.get("auth_display_name") or st.session_state.get("auth_user_id") or ""
    raw = json.dumps(st.session_state.get("chat", []), ensure_ascii=False, sort_keys=True).encode("utf-8")
    h = hashlib.sha256(raw).hexdigest()
    if st.session_state.get("_pdf_chat_hash") != h:
        st.session_state["_pdf_chat_hash"] = h
        st.session_state["_pdf_bytes"] = build_session_pdf_bytes(title, user_label, st.session_state.get("chat", []))
    return st.session_state.get("_pdf_bytes") or b""
# endregion


# region [Auth: ID/PW in secrets.toml]
import hmac
import hashlib
from typing import Dict, Optional

def _load_auth_users_from_secrets() -> Dict[str, dict]:
    """Load users from Streamlit secrets.

    Supports:
      - [[users]] ... at root
      - [auth] ... with users list (depending on secrets layout)
    """
    users = []
    try:
        if "users" in st.secrets:
            users = list(st.secrets.get("users") or [])
        elif "auth" in st.secrets and isinstance(st.secrets.get("auth"), dict) and "users" in st.secrets["auth"]:
            users = list(st.secrets["auth"].get("users") or [])
    except Exception:
        users = []

    out = {}
    for u in users:
        if not isinstance(u, dict):
            continue
        uid = (u.get("id") or "").strip()
        if not uid:
            continue
        out[uid] = u
    return out

def _get_auth_pepper() -> str:
    try:
        if "AUTH_PEPPER" in st.secrets:
            return str(st.secrets.get("AUTH_PEPPER") or "")
        if "auth" in st.secrets and isinstance(st.secrets.get("auth"), dict):
            return str(st.secrets["auth"].get("pepper") or "")
    except Exception:
        pass
    return ""

def _pbkdf2_sha256_verify(password: str, encoded: str, pepper: str = "") -> bool:
    """Verify 'pbkdf2_sha256$iters$salt_b64$dk_b64'"""
    try:
        parts = encoded.split("$")
        if len(parts) != 4 or parts[0] != "pbkdf2_sha256":
            return False
        iters = int(parts[1])
        salt = base64.b64decode(parts[2].encode("utf-8"))
        expect = base64.b64decode(parts[3].encode("utf-8"))
        dk = hashlib.pbkdf2_hmac("sha256", (password + pepper).encode("utf-8"), salt, iters, dklen=len(expect))
        return hmac.compare_digest(dk, expect)
    except Exception:
        return False

def verify_user_password(user_rec: dict, password: str) -> bool:
    pepper = _get_auth_pepper()
    pw_hash = (user_rec.get("pw_hash") or "").strip()

    # Recommended: pbkdf2_sha256$iters$salt_b64$dk_b64
    if pw_hash.startswith("pbkdf2_sha256$"):
        return _pbkdf2_sha256_verify(password, pw_hash, pepper=pepper)

    # Legacy fallback: plain 'pw'
    pw_plain = user_rec.get("pw")
    if isinstance(pw_plain, str) and pw_plain:
        return hmac.compare_digest(pw_plain, password)

    return False

def get_current_user() -> Optional[dict]:
    uid = st.session_state.get("auth_user_id")
    users = st.session_state.get("_auth_users_cache") or _load_auth_users_from_secrets()
    st.session_state["_auth_users_cache"] = users
    return users.get(uid) if uid else None

def is_authenticated() -> bool:
    return bool(st.session_state.get("auth_ok") and st.session_state.get("auth_user_id"))

def _qp_get() -> dict:
    """Query params helper (supports both old/new Streamlit APIs)."""
    try:
        # Streamlit >= 1.30
        return dict(st.query_params)
    except Exception:
        try:
            return st.experimental_get_query_params()
        except Exception:
            return {}

def _qp_set(**kwargs):
    """Set query params helper (supports both old/new Streamlit APIs)."""
    # Normalize: remove keys with None/""/[] values
    cleaned = {}
    for k, v in kwargs.items():
        if v is None:
            continue
        if isinstance(v, (list, tuple)):
            if len(v) == 0:
                continue
            cleaned[k] = list(v)
        else:
            s = str(v).strip()
            if s == "":
                continue
            cleaned[k] = s

    try:
        st.query_params.clear()
        for k, v in cleaned.items():
            st.query_params[k] = v
        return
    except Exception:
        pass

    try:
        st.experimental_set_query_params(**cleaned)
    except Exception:
        return

def _b64url_encode(b: bytes) -> str:
    return base64.urlsafe_b64encode(b).decode("utf-8").rstrip("=")

def _b64url_decode(s: str) -> bytes:
    pad = "=" * (-len(s) % 4)
    return base64.urlsafe_b64decode((s + pad).encode("utf-8"))

def _auth_signing_secret() -> bytes:
    # Prefer pepper; fallback to repo token; fallback to a fixed dev string (last resort).
    pepper = _get_auth_pepper()
    secret = pepper or str(st.secrets.get("AUTH_SIGNING_SECRET", "") or "") or (GITHUB_TOKEN or "") or "dev-secret"
    return secret.encode("utf-8")

def _make_auth_token(user_id: str, ttl_hours: int = None) -> str:
    ttl = ttl_hours if ttl_hours is not None else int(st.secrets.get("AUTH_TOKEN_TTL_HOURS", 24*14) or (24*14))
    exp = int(time.time() + max(60, ttl * 3600))
    payload = {"uid": user_id, "exp": exp}
    raw = json.dumps(payload, separators=(",", ":"), ensure_ascii=False).encode("utf-8")
    body = _b64url_encode(raw)
    sig = hmac.new(_auth_signing_secret(), body.encode("utf-8"), hashlib.sha256).digest()
    return f"{body}.{_b64url_encode(sig)}"

def _verify_auth_token(token: str) -> Optional[dict]:
    try:
        if not token or "." not in token:
            return None
        body, sig = token.split(".", 1)
        expect = hmac.new(_auth_signing_secret(), body.encode("utf-8"), hashlib.sha256).digest()
        if not hmac.compare_digest(_b64url_decode(sig), expect):
            return None
        payload = json.loads(_b64url_decode(body).decode("utf-8"))
        if not isinstance(payload, dict):
            return None
        if int(payload.get("exp", 0)) < int(time.time()):
            return None
        uid = (payload.get("uid") or "").strip()
        if not uid:
            return None
        return payload
    except Exception:
        return None

def _logout_and_clear():
    # Keep query params clean
    _qp_set()  # clears all
    # clear in-memory session
    _reset_chat_only(keep_auth=False)

def require_auth():
    """Gate the app behind a login screen if users are configured in secrets.

    - ë¡œê·¸ì¸ ì„±ê³µ ì‹œ URL query param(auth=...)ì— ì„œëª… í† í°ì„ ì‹¬ì–´ì„œ ìƒˆë¡œê³ ì¹¨ì—ë„ ë¡œê·¸ì¸ ìœ ì§€
    - ë¡œê·¸ì•„ì›ƒì€ ì‚¬ì´ë“œë°” 'ë¡œê·¸ì•„ì›ƒ' ë²„íŠ¼ìœ¼ë¡œ ì²˜ë¦¬(ê°™ì€ ì°½ì—ì„œ ìƒíƒœ ì´ˆê¸°í™”)
    """
    users = st.session_state.get("_auth_users_cache") or _load_auth_users_from_secrets()
    st.session_state["_auth_users_cache"] = users
    auth_enabled = bool(users)

    if not auth_enabled:
        return  # no users configured -> open access

    # Handle logout via query param
    qp = _qp_get()
    if "logout" in qp:
        _logout_and_clear()

    # Already authenticated in this session?
    if is_authenticated():
        u = get_current_user() or {}
        if u and (u.get("active") is False):
            st.session_state.pop("auth_ok", None)
            st.session_state.pop("auth_user_id", None)
        else:
            return

    # Try restore from signed token in query params
    token = None
    try:
        if "auth" in qp:
            token = qp.get("auth")
            if isinstance(token, list):
                token = token[0] if token else None
    except Exception:
        token = None

    payload = _verify_auth_token(str(token or ""))
    if payload:
        uid = payload["uid"]
        rec = users.get(uid)
        if rec and (rec.get("active") is not False):
            st.session_state["auth_ok"] = True
            st.session_state["auth_user_id"] = uid
            st.session_state["auth_role"] = rec.get("role", "user")
            st.session_state["auth_display_name"] = rec.get("display_name", uid)
            st.session_state["client_instance_id"] = st.session_state.get("client_instance_id") or uuid4().hex[:10]
            return

    # --- Login Screen (Centered / Clean) ---
    c1, c2, c3 = st.columns([1.2, 1.0, 1.2])
    with c2:
        st.markdown("<div style='height:10vh;'></div>", unsafe_allow_html=True)

        # ì•± ì´ë¦„
        st.markdown(
            """
            <div style="text-align:center;">
              <h1 style="font-size:2.0rem; font-weight:700; margin:0;
                         background:-webkit-linear-gradient(45deg,#4285F4,#9B72CB,#D96570,#F2A60C);
                         -webkit-background-clip:text; -webkit-text-fill-color:transparent;">
                ğŸ’¬ ìœ íŠœë¸Œ ëŒ“ê¸€ë¶„ì„: AI ì±—ë´‡
              </h1>
            </div>
            """,
            unsafe_allow_html=True,
        )

        # ë¡œê·¸ì¸ íƒ€ì´í‹€
        st.markdown(
            "<div style='text-align:center; margin-top:0.9rem; margin-bottom:0.6rem;'>"
            "<h2 style='font-size:1.3rem; font-weight:650; margin:0; color:#111827;'>ë¡œê·¸ì¸</h2>"
            "</div>",
            unsafe_allow_html=True,
        )

        with st.form("login_form", clear_on_submit=False):
            uid = st.text_input("ID", value="", placeholder="ì•„ì´ë””")
            pw = st.text_input("Password", value="", type="password", placeholder="ë¹„ë°€ë²ˆí˜¸")
            submitted = st.form_submit_button("ë¡œê·¸ì¸", use_container_width=True)

        if submitted:
            uid = (uid or "").strip()
            rec = users.get(uid)
            if (not rec) or rec.get("active") is False:
                st.error("ID ë˜ëŠ” ë¹„ë°€ë²ˆí˜¸ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                st.stop()
            if not verify_user_password(rec, pw):
                st.error("ID ë˜ëŠ” ë¹„ë°€ë²ˆí˜¸ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                st.stop()

            st.session_state["auth_ok"] = True
            st.session_state["auth_user_id"] = uid
            st.session_state["auth_role"] = rec.get("role", "user")
            st.session_state["auth_display_name"] = rec.get("display_name", uid)
            st.session_state["client_instance_id"] = st.session_state.get("client_instance_id") or uuid4().hex[:10]

            # persist login in query params
            tok = _make_auth_token(uid)
            _qp_set(auth=tok)
            return

    st.stop()
# endregion



# region [Helper Classes]
class RotatingKeys:
    def __init__(self, keys, state_key: str, on_rotate=None):
        self.keys = [k.strip() for k in (keys or []) if isinstance(k, str) and k.strip()][:10]
        self.state_key = state_key
        self.on_rotate = on_rotate

        idx = st.session_state.get(state_key, 0)
        self.idx = 0 if not self.keys else (idx % len(self.keys))
        st.session_state[state_key] = self.idx

    def current(self):
        return self.keys[self.idx % len(self.keys)] if self.keys else None

    def rotate(self):
        if not self.keys:
            return
        self.idx = (self.idx + 1) % len(self.keys)
        st.session_state[self.state_key] = self.idx
        if callable(self.on_rotate):
            self.on_rotate(self.idx, self.current())

class RotatingYouTube:
    def __init__(self, keys, state_key="yt_key_idx"):
        self.rot = RotatingKeys(keys, state_key)
        self.service = None
        self._build()

    def _build(self):
        key = self.rot.current()
        if not key:
            raise RuntimeError("YouTube API Keyê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
        self.service = build("youtube", "v3", developerKey=key)

    def execute(self, factory):
        # [ìˆ˜ì •] í‚¤ ê°œìˆ˜ë§Œí¼ ë°˜ë³µí•´ì„œ ì¬ì‹œë„ (ëª¨ë“  í‚¤ë¥¼ ë‹¤ ì°”ëŸ¬ë´„)
        max_retries = len(self.rot.keys)
        last_error = None

        for _ in range(max_retries + 1):
            try:
                return factory(self.service).execute()
            except HttpError as e:
                last_error = e
                status = getattr(getattr(e, 'resp', None), 'status', None)
                msg = (getattr(e, 'content', b'').decode('utf-8', 'ignore') or '').lower()
                
                # 403(Quota) ë˜ëŠ” 429(Rate Limit) ë°œìƒ ì‹œì—ë§Œ ë¡œí…Œì´ì…˜
                if status in (403, 429) and any(t in msg for t in ["quota", "rate", "limit"]):
                    print(f"âš ï¸ [YouTube API] í‚¤ ë§Œë£Œ/ì œí•œ ê°ì§€. ë‹¤ìŒ í‚¤ë¡œ êµì²´ ì‹œë„... (Current: {self.rot.idx})")
                    self.rot.rotate() # ë‹¤ìŒ í‚¤ë¡œ ì¸ë±ìŠ¤ ë³€ê²½
                    self._build()     # ì„œë¹„ìŠ¤ ì¬êµ¬ì¶•
                    continue          # ë£¨í”„ ë‹¤ì‹œ ì‹¤í–‰ (ì¬ì‹œë„)
                
                # ì¿¼í„° ë¬¸ì œê°€ ì•„ë‹Œ ë‹¤ë¥¸ ì—ëŸ¬(400, 404 ë“±)ë©´ ì¦‰ì‹œ ì—ëŸ¬ ë°œìƒ
                raise e
        
        # ëª¨ë“  í‚¤ë¥¼ ë‹¤ ì¨ë´¤ëŠ”ë°ë„ ì•ˆ ë˜ë©´ ë§ˆì§€ë§‰ ì—ëŸ¬ ë°œìƒ
        raise last_error
# endregion

# region [GitHub & Session Management]
def _gh_headers(token: str):
    # Fine-grained PAT í˜¸í™˜ì„ ìœ„í•´ Bearer ìš°ì„ 
    auth = f"Bearer {token}" if token else ""
    return {
        "Authorization": auth,
        "Accept": "application/vnd.github+json",
        "X-GitHub-Api-Version": "2022-11-28",
        "User-Agent": "ytcc-chatbot"
    }

def github_upload_file(repo, branch, path_in_repo, local_path, token):
    url = f"https://api.github.com/repos/{repo}/contents/{path_in_repo}"
    with open(local_path, "rb") as f:
        content = base64.b64encode(f.read()).decode()

    headers = _gh_headers(token)
    get_resp = requests.get(url + f"?ref={branch}", headers=headers)
    sha = get_resp.json().get("sha") if get_resp.ok else None

    data = {
        "message": f"archive: {os.path.basename(path_in_repo)}",
        "content": content,
        "branch": branch
    }
    if sha:
        data["sha"] = sha

    resp = requests.put(url, headers=headers, json=data)
    resp.raise_for_status()
    return resp.json()


def github_list_dir(repo, branch, folder, token):
    url = f"https://api.github.com/repos/{repo}/contents/{folder}?ref={branch}"
    resp = requests.get(url, headers=_gh_headers(token))
    if resp.ok:
        return [item['name'] for item in resp.json() if item['type'] == 'dir']
    return []

def github_download_file(repo, branch, path_in_repo, token, local_path):
    url = f"https://api.github.com/repos/{repo}/contents/{path_in_repo}?ref={branch}"
    resp = requests.get(url, headers=_gh_headers(token))
    if resp.ok:
        os.makedirs(os.path.dirname(local_path), exist_ok=True)
        with open(local_path, "wb") as f:
            f.write(base64.b64decode(resp.json()["content"]))
        return True
    return False


# region [PGC Cache: Auto Sync & Search]
def _cache_local_dir() -> str:
    """PGC ìºì‹œ í´ë”(ë ˆí¬ ë‚´ pgc_cache/)."""
    os.makedirs(PGC_CACHE_DIR, exist_ok=True)
    return PGC_CACHE_DIR

def _extract_vid_from_cache_item(obj):
    """ìºì‹œ JSON ë‚´ë¶€ êµ¬ì¡°ê°€ ë‹¬ë¼ë„ ìµœëŒ€í•œ video_idë¥¼ ë½‘ì•„ëƒ…ë‹ˆë‹¤."""
    if not isinstance(obj, dict):
        return None, None, None
    vid = obj.get("video_id") or obj.get("videoId") or obj.get("id") or obj.get("videoId ")
    title = obj.get("title") or (obj.get("snippet") or {}).get("title") or ""
    desc = obj.get("description") or (obj.get("snippet") or {}).get("description") or ""
    return (vid, title or "", desc or "")

def normalize_text_for_search(text: str) -> str:
    """[í•µì‹¬] ë„ì–´ì“°ê¸°/íŠ¹ìˆ˜ë¬¸ì ë¬´ì‹œí•˜ê³  ê²€ìƒ‰ (ytan ìŠ¤íƒ€ì¼)"""
    if not text: return ""
    return re.sub(r'[^a-zA-Z0-9ê°€-í£]', '', text).lower()

def hashtagify_keyword(keyword: str) -> str:
    """UGC ê²€ìƒ‰ìš©: í‚¤ì›Œë“œ ì•ì— #ì„ ë¶™ì—¬ ê²€ìƒ‰ ì •í™•ë„ë¥¼ ë†’ì„."""
    kw = (keyword or "").strip()
    if not kw:
        return ""
    return kw if kw.startswith("#") else f"#{kw}"

def load_pgc_video_ids_by_keyword(keyword: str, start_dt: datetime = None, end_dt: datetime = None):
    """
    ë¡œì»¬ ìºì‹œ JSONì—ì„œ keywordë¡œ PGC ì˜ìƒ í›„ë³´ ì°¾ê¸°.
    [ìˆ˜ì •] start_dt, end_dtê°€ ìˆìœ¼ë©´ 'publishedAt'ì„ í™•ì¸í•˜ì—¬ ê¸°ê°„ í•„í„°ë§ ìˆ˜í–‰.
    """
    keyword = (keyword or "").strip()
    if not keyword:
        return []

    cache_dir = _cache_local_dir()
    files = []
    for fn in os.listdir(cache_dir):
        if re.fullmatch(r"cache_token_.*\.json", fn):
            files.append(os.path.join(cache_dir, fn))

    vids = []
    kw_norm = normalize_text_for_search(keyword)

    for fp in files:
        try:
            with open(fp, "r", encoding="utf-8") as f:
                data = json.load(f)
        except Exception:
            continue

        candidates = []
        if isinstance(data, list):
            candidates = data
        elif isinstance(data, dict):
            if isinstance(data.get("videos"), list):
                candidates = data.get("videos", [])
            elif isinstance(data.get("items"), list):
                candidates = data.get("items", [])
            else:
                candidates = [data]

        for it in candidates:
            # 1. ë‚ ì§œ í•„í„°ë§ (publishedAt í™•ì¸) - ì—¬ê¸°ê°€ í•µì‹¬ ìˆ˜ì • ì‚¬í•­
            if start_dt or end_dt:
                pub_str = it.get("date")  # âœ… publishedAt â†’ date
                if not pub_str:
                    continue  
                try:
                    pub_dt = datetime.fromisoformat(pub_str.replace("Z", "+00:00"))

                    if start_dt and pub_dt < start_dt:
                        continue
                    if end_dt and pub_dt > end_dt:
                        continue
                except Exception:
                    continue

            # 2. í‚¤ì›Œë“œ ë§¤ì¹­
            vid, title, desc = _extract_vid_from_cache_item(it)
            if not vid or not YTB_ID_RE.fullmatch(str(vid)):
                continue
            
            title_norm = normalize_text_for_search(title)
            desc_norm = normalize_text_for_search(desc)
            
            if (kw_norm in title_norm) or (kw_norm in desc_norm):
                vids.append(str(vid))

    return list(dict.fromkeys(vids))
# endregion


def github_delete_folder(repo, branch, folder_path, token):
    contents_url = f"https://api.github.com/repos/{repo}/contents/{folder_path}?ref={branch}"
    headers = _gh_headers(token)
    resp = requests.get(contents_url, headers=headers)
    if not resp.ok:
        return
    for item in resp.json():
        delete_url = f"https://api.github.com/repos/{repo}/contents/{item['path']}"
        data = {"message": f"delete: {item['name']}", "sha": item['sha'], "branch": branch}
        requests.delete(delete_url, headers=headers, json=data).raise_for_status()

def github_rename_session(user_id: str, old_name: str, new_name: str, token):
    contents_url = f"https://api.github.com/repos/{GITHUB_REPO}/contents/sessions/{user_id}/{old_name}?ref={GITHUB_BRANCH}"
    resp = requests.get(contents_url, headers=_gh_headers(token))
    resp.raise_for_status()
    files_to_move = resp.json()

    for item in files_to_move:
        filename = item['name']
        local_path = os.path.join(SESS_DIR, filename)
        if not github_download_file(GITHUB_REPO, GITHUB_BRANCH, item['path'], token, local_path):
            raise Exception(f"Failed to download {filename} from {old_name}")
        github_upload_file(GITHUB_REPO, GITHUB_BRANCH, f"sessions/{user_id}/{new_name}/{filename}", local_path, token)

    github_delete_folder(GITHUB_REPO, GITHUB_BRANCH, f"sessions/{user_id}/{old_name}", token)

def _session_base_keyword() -> str:
    schema = st.session_state.get("last_schema", {}) or {}
    kw = (schema.get("keywords") or ["ì„¸ì…˜"])[0]
    kw = (kw or "").strip()
    # í•œê¸€/ì˜ë¬¸/ìˆ«ìë§Œ ë‚¨ê¸°ê³ (ê³µë°± ì œê±°), ë„ˆë¬´ ê¸¸ë©´ ì»·
    base = re.sub(r"[^0-9A-Za-zê°€-í£]", "", kw)
    base = base[:12] if base else "ì„¸ì…˜"
    return base

def _next_session_number(user_id: str, base: str) -> int:
    """ê°™ì€ í‚¤ì›Œë“œ(base)ë¡œ ì €ì¥ëœ ì„¸ì…˜ì´ ìˆìœ¼ë©´ ë’¤ ìˆ«ìë¥¼ ì¦ê°€."""
    try:
        if not all([GITHUB_TOKEN, GITHUB_REPO]):
            return 1
        sessions = github_list_dir(GITHUB_REPO, GITHUB_BRANCH, f"sessions/{user_id}", GITHUB_TOKEN) or []
    except Exception:
        sessions = []

    pat = re.compile(rf"^{re.escape(base)}(\d+)$")
    max_n = 0
    for s in sessions:
        m = pat.match(str(s))
        if m:
            try:
                max_n = max(max_n, int(m.group(1)))
            except Exception:
                pass
    return max_n + 1 if max_n > 0 else 1

def _build_session_name() -> str:
    # ì´ë¯¸ ë¶ˆëŸ¬ì˜¨ ì„¸ì…˜ì´ë©´ ê°™ì€ ì´ë¦„ ìœ ì§€
    if st.session_state.get("loaded_session_name"):
        return st.session_state.loaded_session_name

    user_id = st.session_state.get('auth_user_id') or 'public'
    base = _session_base_keyword()
    n = _next_session_number(user_id, base)
    return f"{base}{n}"


def save_current_session_to_github():
    if not all([GITHUB_REPO, GITHUB_TOKEN, st.session_state.chat, st.session_state.last_csv]):
        return False, "ì €ì¥í•  ë°ì´í„°ê°€ ì—†ê±°ë‚˜ GitHub ì„¤ì •ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤."

    sess_name = _build_session_name()
    user_id = st.session_state.get('auth_user_id') or 'public'
    local_dir = os.path.join(SESS_DIR, user_id, sess_name)
    os.makedirs(local_dir, exist_ok=True)

    try:
        meta_path = os.path.join(local_dir, "qa.json")
        meta_data = {
            "chat": st.session_state.chat,
            "last_schema": st.session_state.last_schema,
            "sample_text": st.session_state.sample_text
        }
        with open(meta_path, "w", encoding="utf-8") as f:
            json.dump(meta_data, f, ensure_ascii=False, indent=2)

        comments_path = os.path.join(local_dir, "comments.csv")
        videos_path = os.path.join(local_dir, "videos.csv")

        os.system(f'cp "{st.session_state.last_csv}" "{comments_path}"')
        if st.session_state.last_df is not None:
            st.session_state.last_df.to_csv(videos_path, index=False, encoding="utf-8-sig")

        github_upload_file(GITHUB_REPO, GITHUB_BRANCH, f"sessions/{user_id}/{sess_name}/qa.json", meta_path, GITHUB_TOKEN)
        github_upload_file(GITHUB_REPO, GITHUB_BRANCH, f"sessions/{user_id}/{sess_name}/comments.csv", comments_path, GITHUB_TOKEN)
        if os.path.exists(videos_path):
            github_upload_file(GITHUB_REPO, GITHUB_BRANCH, f"sessions/{user_id}/{sess_name}/videos.csv", videos_path, GITHUB_TOKEN)

        st.session_state.loaded_session_name = sess_name
        return True, sess_name

    except Exception as e:
        return False, f"ì €ì¥ ì‹¤íŒ¨: {e}"

def load_session_from_github(sess_name: str):
    with st.spinner(f"ì„¸ì…˜ '{sess_name}' ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
        try:
            user_id = st.session_state.get('auth_user_id') or 'public'
            local_dir = os.path.join(SESS_DIR, user_id, sess_name)
            qa_ok = github_download_file(GITHUB_REPO, GITHUB_BRANCH, f"sessions/{user_id}/{sess_name}/qa.json", GITHUB_TOKEN, os.path.join(local_dir, "qa.json"))
            comments_ok = github_download_file(GITHUB_REPO, GITHUB_BRANCH, f"sessions/{user_id}/{sess_name}/comments.csv", GITHUB_TOKEN, os.path.join(local_dir, "comments.csv"))
            videos_ok = github_download_file(GITHUB_REPO, GITHUB_BRANCH, f"sessions/{user_id}/{sess_name}/videos.csv", GITHUB_TOKEN, os.path.join(local_dir, "videos.csv"))

            if not (qa_ok and comments_ok):
                st.error("ì„¸ì…˜ í•µì‹¬ íŒŒì¼ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                return
            # ë¡œê·¸ì¸ ìƒíƒœëŠ” ìœ ì§€í•œ ì±„ë¡œ, ëŒ€í™”/ë¶„ì„ ìƒíƒœë§Œ ì´ˆê¸°í™”
            _reset_chat_only(keep_auth=True)

            with open(os.path.join(local_dir, "qa.json"), "r", encoding="utf-8") as f:
                meta = json.load(f)

            st.session_state.update({
                "chat": meta.get("chat", []),
                "last_schema": meta.get("last_schema", None),
                "last_csv": os.path.join(local_dir, "comments.csv"),
                "last_df": pd.read_csv(os.path.join(local_dir, "videos.csv")) if videos_ok and os.path.exists(os.path.join(local_dir, "videos.csv")) else pd.DataFrame(),
                "loaded_session_name": sess_name,
                "sample_text": meta.get("sample_text", "")
            })
        except Exception as e:
            st.error(f"ì„¸ì…˜ ë¡œë“œ ì‹¤íŒ¨: {e}")

# ì„¸ì…˜ ë¡œë“œ/ì‚­ì œ/ì´ë¦„ë³€ê²½ íŠ¸ë¦¬ê±° ì²˜ë¦¬
if 'session_to_load' in st.session_state:
    load_session_from_github(st.session_state.pop('session_to_load'))
    st.rerun()

if 'session_to_delete' in st.session_state:
    sess_name = st.session_state.pop('session_to_delete')
    with st.spinner(f"ì„¸ì…˜ '{sess_name}' ì‚­ì œ ì¤‘..."):
        user_id = st.session_state.get("auth_user_id") or "public"
        github_delete_folder(GITHUB_REPO, GITHUB_BRANCH, f"sessions/{user_id}/{sess_name}", GITHUB_TOKEN)
    st.success("ì„¸ì…˜ ì‚­ì œ ì™„ë£Œ.")
    time.sleep(1)
    st.rerun()

if 'session_to_rename' in st.session_state:
    old, new = st.session_state.pop('session_to_rename')
    if old and new and old != new:
        with st.spinner("ì´ë¦„ ë³€ê²½ ì¤‘..."):
            try:
                user_id = st.session_state.get("auth_user_id") or "public"
                github_rename_session(user_id, old, new, GITHUB_TOKEN)
                st.success("ì´ë¦„ ë³€ê²½ ì™„ë£Œ!")
            except Exception as e:
                st.error(f"ë³€ê²½ ì‹¤íŒ¨: {e}")
        time.sleep(1)
        st.rerun()
# endregion

# region [Data Processing & Utils]
def serialize_comments_for_llm_from_file(csv_path: str,
                                         max_chars_per_comment=280,
                                         max_total_chars=420_000,
                                         top_n=1000,
                                         random_n=1000,
                                         dedup_key="text"):
    """CSV(ëŒ“ê¸€)ì—ì„œ LLM ì…ë ¥ìš© ìƒ˜í”Œ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•œë‹¤.

    - ì¶”ì¶œ ê¸°ì¤€(ê¸°ë³¸):
      1) likeCount ìƒìœ„ top_nê°œ + 2) ë‚˜ë¨¸ì§€ì—ì„œ random_nê°œ ëœë¤
    - LLM ì…ë ¥ ì•ˆì •í™”ë¥¼ ìœ„í•´:
      - ëŒ“ê¸€ë‹¹ max_chars_per_comment ê¸€ì ì»·
      - ì „ì²´ max_total_chars ê¸€ì ì»·(ì´ ì„ ì—ì„œ ë¼ì¸ ìƒì„± ì¤‘ë‹¨)

    Returns:
      (sample_text, sample_line_count, sample_total_chars, meta_dict)
    """
    if not os.path.exists(csv_path):
        return "", 0, 0, {"error": "csv_not_found"}

    try:
        df_all = pd.read_csv(csv_path)
    except Exception:
        return "", 0, 0, {"error": "csv_read_failed"}

    if df_all.empty:
        return "", 0, 0, {"error": "csv_empty"}

    # ì´ ìˆ˜ì§‘ ëŒ“ê¸€ ìˆ˜(=CSV rows)
    total_rows = len(df_all)

    # (ì„ íƒ) ì¤‘ë³µ ì œê±° ê¸°ì¤€(ê¸°ë³¸: text)
    unique_rows = None
    try:
        if dedup_key in df_all.columns:
            unique_rows = df_all[dedup_key].astype(str).str.strip().replace("", pd.NA).dropna().nunique()
    except Exception:
        unique_rows = None

    # ì¸ê¸° ëŒ“ê¸€ + ëœë¤ ëŒ“ê¸€ ìƒ˜í”Œë§
    df_top_likes = df_all.sort_values("likeCount", ascending=False).head(top_n)
    df_remaining = df_all.drop(df_top_likes.index)

    if not df_remaining.empty:
        take_n = min(random_n, len(df_remaining))
        df_random = df_remaining.sample(n=take_n, random_state=42)
    else:
        df_random = pd.DataFrame()

    df_sample = pd.concat([df_top_likes, df_random], ignore_index=True)
    sampled_target = len(df_sample)

    lines, total_chars = [], 0
    used_top = len(df_top_likes)
    used_random = len(df_random)

    for _, r in df_sample.iterrows():
        if total_chars >= max_total_chars:
            break

        raw_text = str(r.get("text", "") or "").replace("\n", " ")
        prefix = f"[{'R' if int(r.get('isReply', 0)) == 1 else 'T'}|â™¥{int(r.get('likeCount', 0))}] "
        author_clean = str(r.get('author', '')).replace('\n', ' ')
        prefix += f"{author_clean}: "

        body = raw_text[:max_chars_per_comment] + 'â€¦' if len(raw_text) > max_chars_per_comment else raw_text

        line = prefix + body
        lines.append(line)
        total_chars += len(line) + 1

    meta = {
        "total_rows": total_rows,
        "unique_rows": unique_rows,
        "top_n": int(top_n),
        "random_n": int(random_n),
        "used_top": int(used_top),
        "used_random": int(used_random),
        "sampled_target": int(sampled_target),
        "llm_input_lines": int(len(lines)),
        "llm_input_chars": int(total_chars),
        "max_chars_per_comment": int(max_chars_per_comment),
        "max_total_chars": int(max_total_chars),
        "dedup_key": str(dedup_key),
    }
    return "\n".join(lines), len(lines), total_chars, meta


def tidy_answer(text: str) -> str:
    """
    1. ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡(```html) ì œê±°
    2. [í•µì‹¬] HTML íƒœê·¸ ì•ì˜ ë“¤ì—¬ì“°ê¸°(ê³µë°±)ë¥¼ ê°•ì œë¡œ ì œê±°í•˜ì—¬ ì½”ë“œ ë¸”ë¡ìœ¼ë¡œ ì¸ì‹ë˜ëŠ” ê²ƒì„ ë°©ì§€
    3. ë¶ˆí•„ìš”í•œ ì œëª© ì œê±°
    """
    if not text:
        return ""
    
    # 1. ```html, ``` ì œê±°
    text = re.sub(r"^```html", "", text, flags=re.MULTILINE | re.IGNORECASE)
    text = re.sub(r"^```", "", text, flags=re.MULTILINE)
    
    # 2. [ì‹ ê·œ ê¸°ëŠ¥] HTML íƒœê·¸ë¡œ ì‹œì‘í•˜ëŠ” ì¤„ì˜ ì• ê³µë°± ì œê±° (ë“¤ì—¬ì“°ê¸° ì‚­ì œ)
    #    ì˜ˆ: "    <div..." -> "<div..."
    #    ì´ê²Œ ì—†ìœ¼ë©´ Streamlitì´ 'ì½”ë“œ ë¸”ë¡'ìœ¼ë¡œ ì˜¤í•´í•´ì„œ Raw HTMLì„ ë³´ì—¬ì¤Œ
    text = re.sub(r"^\s+(?=<)", "", text, flags=re.MULTILINE)
    
    lines = text.splitlines()
    cleaned = []
    
    # 3. ë¶ˆí•„ìš”í•œ ì œëª© ì œê±°
    REMOVE_PATTERN = re.compile(r"ìœ íŠœë¸Œ\s*ëŒ“ê¸€\s*ë¶„ì„|ë³´ê³ ì„œ\s*ì‘ì„±|ë¶„ì„\s*ê²°ê³¼", re.IGNORECASE)

    for line in lines:
        if not line.strip():
            cleaned.append(line)
            continue
        if REMOVE_PATTERN.search(line) and len(line) < 50:
            continue
        cleaned.append(line)

    return "\n".join(cleaned).strip()

YTB_ID_RE = re.compile(r"[A-Za-z0-9_-]{11}")

def extract_video_ids_from_text(text: str) -> list:
    if not text:
        return []
    ids = set()
    for m in re.finditer(r"https?://youtu\.be/([A-Za-z0-9_-]{11})", text):
        ids.add(m.group(1))
    for m in re.finditer(r"https?://(?:www\.)?youtube\.com/shorts/([A-Za-z0-9_-]{11})", text):
        ids.add(m.group(1))
    for m in re.finditer(r"https?://(?:www\.)?youtube\.com/watch\?[^ \n]+", text):
        url = m.group(0)
        try:
            qs = dict((kv.split("=", 1) + [""])[:2] for kv in url.split("?", 1)[1].split("&"))
            v = qs.get("v", "")
            if YTB_ID_RE.fullmatch(v):
                ids.add(v)
        except Exception:
            pass
    return list(ids)

def strip_urls(s: str) -> str:
    if not s:
        return ""
    s = re.sub(r"https?://\S+", " ", s)
    return re.sub(r"\s+", " ", s).strip()
# endregion

# region [API Integrations: Gemini & YouTube]
# ==============================================================================
# [Gemini í˜¸ì¶œ í•¨ìˆ˜] - ì¼ë°˜ í˜¸ì¶œ & ìŠ¤ë§ˆíŠ¸ ìºì‹± í˜¸ì¶œ
# ==============================================================================
def call_gemini_rotating(model_name, keys, system_instruction, user_payload,
                         timeout_s=120, max_tokens=8192) -> str:
    """ê¸°ì¡´ì˜ ì¼ë°˜(Non-Cached) í˜¸ì¶œ í•¨ìˆ˜"""
    rk = RotatingKeys(keys, "gem_key_idx")
    if not rk.current():
        raise RuntimeError("Gemini API Keyê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")

    real_sys_inst = None if (not system_instruction or not system_instruction.strip()) else system_instruction
    
    from google.generativeai.types import HarmCategory, HarmBlockThreshold
    safety_settings = {
        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
    }

    for _ in range(len(rk.keys) or 1):
        try:
            genai.configure(api_key=rk.current())
            model = genai.GenerativeModel(
                model_name,
                generation_config={"temperature": 0.2, "max_output_tokens": max_tokens},
                system_instruction=real_sys_inst 
            )
            with GeminiInflightSlot():
                resp = model.generate_content(
                    user_payload,
                    request_options={"timeout": timeout_s},
                    safety_settings=safety_settings 
                )
            
            if not resp: return "âš ï¸ AI ì‘ë‹µ ì—†ìŒ"
            try:
                if getattr(resp, "text", None): return resp.text
            except ValueError:
                if resp.prompt_feedback: return f"âš ï¸ [ì°¨ë‹¨] {resp.prompt_feedback}"
            
            if c0 := (getattr(resp, "candidates", None) or [None])[0]:
                if p0 := (getattr(c0, "content", None) and getattr(c0.content, "parts", None) or [None])[0]:
                    if hasattr(p0, "text"): return p0.text
            return "âš ï¸ [ì‹œìŠ¤í…œ] ë‚´ìš© ê³¼ë‹¤ ë˜ëŠ” ì°¨ë‹¨ìœ¼ë¡œ ë‹µë³€ ìƒì„± ì‹¤íŒ¨"

        except Exception as e:
            if isinstance(e, TimeoutError) or "GEMINI_INFLIGHT_TIMEOUT" in str(e):
                return "âš ï¸ í˜„ì¬ ìš”ì²­ì´ ë§ì•„ AI ë¶„ì„ ëŒ€ê¸°ì—´ì´ ê½‰ ì°¼ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            msg = str(e).lower()
            if "429" in msg or "quota" in msg:
                if len(rk.keys) > 1:
                    rk.rotate()
                    continue
            print(f"Gemini API Error: {e}")
            raise e
    return ""

def call_gemini_smart_cache(model_name, keys, system_instruction, user_query, 
                            large_context_text=None, cache_key_in_session="current_cache"):
    """
    [ìŠ¤ë§ˆíŠ¸ ìºì‹± ë¡œì§]
    1. ìºì‹œê°€ ìˆìœ¼ë©´ -> ë¶ˆëŸ¬ì˜¤ê¸° & ìˆ˜ëª…ì—°ì¥(TTL Update)
    2. ìºì‹œê°€ ì—†ê±°ë‚˜ ë§Œë£Œ(404) -> ìƒˆë¡œ ìƒì„±(Resurrection)
    3. í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì§§ìœ¼ë©´ -> ì¼ë°˜ í˜¸ì¶œë¡œ ìë™ ì „í™˜
    """
    rk = RotatingKeys(keys, "gem_key_idx")
    cached_info = st.session_state.get(cache_key_in_session, None)
    
    active_cache = None
    final_model = None
    
    from google.generativeai.types import HarmCategory, HarmBlockThreshold
    safety_settings = {
        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
    }

    # [Case A] ê¸°ì¡´ ìºì‹œ í™œìš© ì‹œë„ (Keep-Alive)
    if cached_info and not large_context_text:
        cache_name = cached_info.get("name")
        creator_key = cached_info.get("key")
        
        # ìºì‹œëŠ” ë§Œë“  í‚¤ë¡œë§Œ ì ‘ê·¼ ê°€ëŠ¥
        genai.configure(api_key=creator_key)
        try:
            active_cache = caching.CachedContent.get(cache_name)
            # ìˆ˜ëª… ì—°ì¥ (+20ë¶„)
            with GeminiInflightSlot():
                active_cache.update(ttl=timedelta(minutes=CACHE_TTL_MINUTES))
            
            final_model = genai.GenerativeModel.from_cached_content(
                cached_content=active_cache,
                generation_config={"temperature": 0.2, "max_output_tokens": GEMINI_MAX_TOKENS}
            )
            # print(f"âœ… [Cache] ìˆ˜ëª… ì—°ì¥ ì„±ê³µ: {cache_name}")
        except Exception as e:
            # 404(ë§Œë£Œ), 403(ê¶Œí•œ) -> ì¬ìƒì„± í•„ìš”
            # print(f"âš ï¸ [Cache] ë§Œë£Œ/ì˜¤ë¥˜ë¡œ ì¬ìƒì„± í•„ìš”: {e}")
            active_cache = None
            
            # ì¬ìƒì„±ì„ ìœ„í•œ ì›ë³¸ ë°ì´í„° ë³µêµ¬
            large_context_text = st.session_state.get("sample_text_full_context", "")
            if not large_context_text:
                return "âš ï¸ [ì˜¤ë¥˜] ì„¸ì…˜ì´ ë§Œë£Œë˜ì–´ ë³µêµ¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ìƒˆë¡œê³ ì¹¨ í•´ì£¼ì„¸ìš”."

    # [Case B] ì‹ ê·œ ìƒì„± ë˜ëŠ” ì¬ìƒì„± (Resurrection)
    if not active_cache and large_context_text:
        # ì„¸ì…˜ì— ì›ë³¸ ë°±ì—… (ì¬ìƒì„±ìš©)
        st.session_state["sample_text_full_context"] = large_context_text

        for _ in range(len(rk.keys)):
            current_key = rk.current()
            genai.configure(api_key=current_key)
            try:
                with GeminiInflightSlot():
                    active_cache = caching.CachedContent.create(
                        model=model_name,
                        display_name=f"ytcc_{uuid4().hex[:8]}",
                        system_instruction=system_instruction,
                        contents=[large_context_text],
                        ttl=timedelta(minutes=CACHE_TTL_MINUTES)
                    )
                
                st.session_state[cache_key_in_session] = {
                    "name": active_cache.name,
                    "key": current_key
                }
                
                final_model = genai.GenerativeModel.from_cached_content(
                    cached_content=active_cache,
                    generation_config={"temperature": 0.2, "max_output_tokens": GEMINI_MAX_TOKENS}
                )
                # print(f"ğŸ†• [Cache] ìƒì„± ì™„ë£Œ: {active_cache.name}")
                break
            except Exception as e:
                msg = str(e).lower()
                # ë‚´ìš©ì´ ë„ˆë¬´ ì§§ìŒ -> ìºì‹± í¬ê¸°í•˜ê³  ì¼ë°˜ í˜¸ì¶œ
                if "too short" in msg or "argument" in msg:
                    # print("â„¹ï¸ [Cache] í…ìŠ¤íŠ¸ê°€ ì§§ì•„ ì¼ë°˜ í˜¸ì¶œë¡œ ì „í™˜")
                    active_cache = None
                    break
                if "429" in msg or "quota" in msg:
                    rk.rotate()
                    continue
                raise e

    # [Execution]
    try:
        if final_model:
            with GeminiInflightSlot():
                resp = final_model.generate_content(user_query, safety_settings=safety_settings)
        else:
            # ìºì‹± ì‹¤íŒ¨/ë¯¸ì‚¬ìš© ì‹œ ì¼ë°˜ í˜¸ì¶œ (Fallback)
            full_payload = f"{system_instruction}\n\n{large_context_text or ''}\n\n{user_query}"
            return call_gemini_rotating(model_name, keys, None, full_payload)

        if resp and resp.text: return resp.text
        return "âš ï¸ [ì‹œìŠ¤í…œ] AI ì‘ë‹µ ì—†ìŒ (ë¹ˆ ë‚´ìš©)"
    except Exception as e:
        if isinstance(e, TimeoutError) or "GEMINI_INFLIGHT_TIMEOUT" in str(e):
            return "âš ï¸ í˜„ì¬ ìš”ì²­ì´ ë§ì•„ AI ë¶„ì„ ëŒ€ê¸°ì—´ì´ ê½‰ ì°¼ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
        return f"âš ï¸ [ì‹œìŠ¤í…œ] ì²˜ë¦¬ ì¤‘ ì—ëŸ¬: {e}"

def yt_search_videos(rt, keyword, max_results, order="viewCount",
                     published_after=None, published_before=None):
    video_ids, token = [], None
    while len(video_ids) < max_results:
        params = {
            "q": keyword, "part": "id", "type": "video", "order": order,
            "maxResults": min(50, max_results - len(video_ids))
        }
        if published_after: params["publishedAfter"] = published_after
        if published_before: params["publishedBefore"] = published_before
        if token: params["pageToken"] = token

        resp = rt.execute(lambda s: s.search().list(**params))
        video_ids.extend(it["id"]["videoId"] for it in resp.get("items", [])
                         if it["id"]["videoId"] not in video_ids)
        if not (token := resp.get("nextPageToken")):
            break
        time.sleep(0.25)
    return video_ids

def yt_video_statistics(rt, video_ids):
    rows = []
    for i in range(0, len(video_ids), 50):
        batch = video_ids[i:i+50]
        if not batch: continue

        resp = rt.execute(lambda s: s.videos().list(part="statistics,snippet,contentDetails", id=",".join(batch)))
        for item in resp.get("items", []):
            stats, snip, cont = item.get("statistics", {}), item.get("snippet", {}), item.get("contentDetails", {})
            dur = cont.get("duration", "")
            h, m, s = re.search(r"(\d+)H", dur), re.search(r"(\d+)M", dur), re.search(r"(\d+)S", dur)
            dur_sec = (int(h.group(1))*3600 if h else 0) + (int(m.group(1))*60 if m else 0) + (int(s.group(1)) if s else 0)

            vid_id = item.get("id")
            rows.append({
                "video_id": vid_id,
                "video_url": f"https://www.youtube.com/watch?v={vid_id}",
                "title": snip.get("title", ""),
                "channelTitle": snip.get("channelTitle", ""),
                "publishedAt": snip.get("publishedAt", ""),
                "duration": dur,
                "shortType": "Shorts" if dur_sec <= 60 else "Clip",
                "viewCount": int(stats.get("viewCount", 0) or 0),
                "likeCount": int(stats.get("likeCount", 0) or 0),
                "commentCount": int(stats.get("commentCount", 0) or 0)
            })
        time.sleep(0.25)
    return rows

def yt_all_replies(rt, parent_id, video_id, title="", short_type="Clip", cap=None):
    replies, token = [], None
    while not (cap is not None and len(replies) >= cap):
        try:
            resp = rt.execute(lambda s: s.comments().list(part="snippet", parentId=parent_id, maxResults=100, pageToken=token, textFormat="plainText"))
        except HttpError: break

        for c in resp.get("items", []):
            sn = c["snippet"]
            replies.append({
                "video_id": video_id, "video_title": title, "shortType": short_type,
                "comment_id": c.get("id", ""), "parent_id": parent_id, "isReply": 1,
                "author": sn.get("authorDisplayName", ""), "text": sn.get("textDisplay", "") or "",
                "publishedAt": sn.get("publishedAt", ""), "likeCount": int(sn.get("likeCount", 0) or 0)
            })
        if not (token := resp.get("nextPageToken")): break
        time.sleep(0.2)
    return replies[:cap] if cap is not None else replies

def yt_all_comments_sync(rt, video_id, title="", short_type="Clip",
                         include_replies=True, max_per_video=None):
    rows, token = [], None
    while not (max_per_video is not None and len(rows) >= max_per_video):
        try:
            resp = rt.execute(lambda s: s.commentThreads().list(part="snippet,replies", videoId=video_id, maxResults=100, pageToken=token, textFormat="plainText"))
        except HttpError: break

        for it in resp.get("items", []):
            top = it["snippet"]["topLevelComment"]["snippet"]
            thread_id = it["snippet"]["topLevelComment"]["id"]
            rows.append({
                "video_id": video_id, "video_title": title, "shortType": short_type,
                "comment_id": thread_id, "parent_id": "", "isReply": 0,
                "author": top.get("authorDisplayName", ""), "text": top.get("textDisplay", "") or "",
                "publishedAt": top.get("publishedAt", ""), "likeCount": int(top.get("likeCount", 0) or 0)
            })
            if include_replies and int(it["snippet"].get("totalReplyCount", 0) or 0) > 0:
                cap = None if max_per_video is None else max(0, max_per_video - len(rows))
                if cap == 0: break
                rows.extend(yt_all_replies(rt, thread_id, video_id, title, short_type, cap=cap))
        if not (token := resp.get("nextPageToken")): break
        time.sleep(0.2)
    return rows[:max_per_video] if max_per_video is not None else rows

def parallel_collect_comments_streaming(video_list, rt_keys, include_replies,
                                        max_total_comments, max_per_video, prog_bar):
    out_csv = os.path.join(BASE_DIR, f"collect_{uuid4().hex}.csv")
    wrote_header, total_written, done, total_videos = False, 0, 0, len(video_list)

    with ThreadPoolExecutor(max_workers=8) as ex:
        futures = {
            ex.submit(yt_all_comments_sync, RotatingYouTube(rt_keys), v["video_id"], v.get("title", ""),
                      v.get("shortType", "Clip"), include_replies, max_per_video): v for v in video_list
        }
        for f in as_completed(futures):
            try:
                if comm := f.result():
                    dfc = pd.DataFrame(comm)
                    dfc.to_csv(out_csv, index=False, mode="a" if wrote_header else "w", header=not wrote_header, encoding="utf-8-sig")
                    wrote_header = True
                    total_written += len(dfc)
            except Exception: pass
            done += 1
            prog_bar.progress(min(0.90, 0.50 + (done / total_videos) * 0.40 if total_videos > 0 else 0.50), text="ëŒ“ê¸€ ìˆ˜ì§‘ì¤‘â€¦")
            if total_written >= max_total_comments: break
    return out_csv, total_written
# endregion


# region [UI Components]
def scroll_to_bottom():
    st_html(
        "<script> "
        "let last_message = document.querySelectorAll('.stChatMessage'); "
        "if (last_message.length > 0) { "
        "  last_message[last_message.length - 1].scrollIntoView({behavior: 'smooth'}); "
        "} "
        "</script>",
        height=0
    )

def render_capture_pdf_button(file_basename: str, label: str = "PDFì €ì¥"):
    """
    ëŒ€í™”ì°½(ì±„íŒ… ë©”ì‹œì§€ ì˜ì—­)ë§Œ 'ìŠ¤í¬ë¦°ìƒ· ê¸°ë°˜'ìœ¼ë¡œ PDF ì €ì¥í•œë‹¤.
    - reportlab í•œê¸€/ë ˆì´ì•„ì›ƒ ì´ìŠˆ íšŒí”¼
    - ìŠ¤í¬ë¡¤ ëê¹Œì§€(ì „ì²´ ë©”ì‹œì§€) í¬í•¨
    - ìš°ì¸¡ ì˜ë¦¼ ë°©ì§€(ìº¡ì³ í­ì„ ë™ì ìœ¼ë¡œ í™•ë³´ + ì¤„ë°”ê¿ˆ ê°•ì œ)
    """

    # íŒŒì¼ëª… ì•ˆì „í™”
    safe = re.sub(r'[\\/:*?"<>|]+', "_", (file_basename or "chat")).strip()
    safe = re.sub(r"\s+", "_", safe) or "chat"

    # Streamlit rerunë§ˆë‹¤ idê°€ ë°”ë€Œë„ë¡ (DOM ì¶©ëŒ ë°©ì§€)
    btn_id = f"ytcc_cap_pdf_{uuid4().hex[:8]}"

    st_html(
        f"""
        <style>
          html, body {{
            margin: 0; padding: 0;
            background: transparent;
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Noto Sans KR", Arial, sans-serif;
          }}
          .ytcc-cap-wrap {{ width: 100%; margin: 0; padding: 0; }}
          /* âœ… 'ì„¸ì…˜ì €ì¥' í†¤ê³¼ ë™ì¼í•˜ê²Œ */
          .ytcc-cap-btn {{
            width: 100%;
            padding: 0.30rem 0.55rem;
            border-radius: 12px;
            border: 1px solid #cdeedb;
            background: #eafaf1;
            color: #127a3a;
            cursor: pointer;
            font-size: 0.72rem;
            font-weight: 650;
            line-height: 1.0;
            box-sizing: border-box;
          }}
          .ytcc-cap-btn:hover {{
            background: #d6f3e4;
            border-color: #bfe8d3;
            color: #0f6a32;
          }}
          .ytcc-cap-btn:disabled {{
            opacity: 0.70;
            cursor: default;
          }}
</style>

        <div class="ytcc-cap-wrap">
          <button id="{btn_id}" class="ytcc-cap-btn">{label}</button>
        </div>

        <script>
        (function() {{
          const btn = document.getElementById("{btn_id}");
          if (!btn) return;

          const PARENT = window.parent;
          const DOC = PARENT.document;

          function ensureScript(src, globalName) {{
            return new Promise((resolve, reject) => {{
              try {{
                if (globalName && PARENT[globalName]) return resolve(true);
                if (DOC.querySelector('script[data-ytcc-src="'+src+'"]')) return resolve(true);
                const s = DOC.createElement('script');
                s.src = src;
                s.async = true;
                s.setAttribute('data-ytcc-src', src);
                s.onload = () => resolve(true);
                s.onerror = () => reject(new Error('load failed: ' + src));
                DOC.head.appendChild(s);
              }} catch (e) {{
                reject(e);
              }}
            }});
          }}

          async function captureToPdf() {{
            btn.disabled = true;
            const originalText = btn.innerText;
            btn.innerText = "ìº¡ì³ì¤‘...";

            try {{
              await ensureScript("https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.4.1/html2canvas.min.js", "html2canvas");
              await ensureScript("https://cdnjs.cloudflare.com/ajax/libs/jspdf/2.5.1/jspdf.umd.min.js", "jspdf");

              const msgs = Array.from(DOC.querySelectorAll('[data-testid="stChatMessage"]'));
              if (!msgs.length) {{
                alert("ìº¡ì³í•  ëŒ€í™”ê°€ ì—†ìŠµë‹ˆë‹¤.");
                return;
              }}

              // âœ… ì²« ì±„íŒ… ë©”ì‹œì§€ í­ì„ ê¸°ì¤€ìœ¼ë¡œ ìº¡ì³ í­ í™•ì¥ (ìš°ì¸¡ ì˜ë¦¼ ë°©ì§€)
              const r = msgs[0].getBoundingClientRect();
              const capW = Math.max(1200, Math.min(1700, (r.width || 1200) + 140));

              const tmp = DOC.createElement('div');
              tmp.id = "ytcc_capture_tmp";
              tmp.style.position = "absolute";
              tmp.style.left = "0px";
              tmp.style.top = "0px";
              tmp.style.transform = "translateX(-20000px)";
              tmp.style.width = capW + "px";
              tmp.style.background = "#ffffff";
              tmp.style.padding = "18px 22px";
              tmp.style.borderRadius = "12px";
              tmp.style.color = "#111827";
              tmp.style.boxSizing = "border-box";
              tmp.style.overflow = "visible";
              tmp.style.overflowWrap = "anywhere";
              tmp.style.wordBreak = "break-word";

              const title = DOC.createElement('div');
              title.style.fontSize = "14px";
              title.style.fontWeight = "800";
              title.style.marginBottom = "6px";
              title.innerText = "ìœ íŠœë¸Œ ëŒ“ê¸€ë¶„ì„: AI ì±—ë´‡ â€” ëŒ€í™” ìº¡ì³";
              tmp.appendChild(title);

              const meta = DOC.createElement('div');
              meta.style.fontSize = "12px";
              meta.style.color = "#6b7280";
              meta.style.marginBottom = "10px";
              meta.innerText = "ìƒì„±ì¼ì‹œ: " + (new Date()).toLocaleString();
              tmp.appendChild(meta);

              msgs.forEach(m => tmp.appendChild(m.cloneNode(true)));
              DOC.body.appendChild(tmp);

              // âœ… ê¸´ URL/ì½”ë“œë¸”ëŸ­ë„ ê°•ì œë¡œ ì¤„ë°”ê¿ˆ (ìš°ì¸¡ ì˜ë¦¼ ë°©ì§€)
              tmp.querySelectorAll("*").forEach(el => {{
                try {{
                  el.style.boxSizing = "border-box";
                  el.style.maxWidth = "100%";
                  el.style.overflowWrap = "anywhere";
                  el.style.wordBreak = "break-word";
                }} catch (e) {{}}
              }});

              const canvas = await PARENT.html2canvas(tmp, {{
                scale: 2,
                useCORS: true,
                backgroundColor: "#ffffff",
                logging: false,
                windowWidth: capW,
              }});

              DOC.body.removeChild(tmp);

              const imgData = canvas.toDataURL("image/png");
              const {{ jsPDF }} = PARENT.jspdf;

              const pdf = new jsPDF("p", "pt", "a4");
              const pageWidth = pdf.internal.pageSize.getWidth();
              const pageHeight = pdf.internal.pageSize.getHeight();

              const imgWidth = pageWidth;
              const imgHeight = (canvas.height * imgWidth) / canvas.width;

              let heightLeft = imgHeight;
              let position = 0;

              pdf.addImage(imgData, "PNG", 0, position, imgWidth, imgHeight);
              heightLeft -= pageHeight;

              while (heightLeft > 0) {{
                position = heightLeft - imgHeight;
                pdf.addPage();
                pdf.addImage(imgData, "PNG", 0, position, imgWidth, imgHeight);
                heightLeft -= pageHeight;
              }}

              pdf.save("{safe}.pdf");
            }} catch (err) {{
              console.error(err);
              alert("PDF ìº¡ì³ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì½˜ì†” ë¡œê·¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.");
            }} finally {{
              btn.disabled = false;
              btn.innerText = originalText;
            }}
          }}

          btn.addEventListener("click", captureToPdf);
        }})();
        </script>
        """,
        height=44,
    )

def render_metadata_and_downloads():
    if not (schema := st.session_state.get("last_schema")):
        return

    kw_main = schema.get("keywords", [])
    start_iso, end_iso = schema.get('start_iso', ''), schema.get('end_iso', '')
    try:
        start_dt_str = datetime.fromisoformat(start_iso).astimezone(KST).strftime('%Y-%m-%d %H:%M')
        end_dt_str   = datetime.fromisoformat(end_iso).astimezone(KST).strftime('%Y-%m-%d %H:%M')
    except (ValueError, TypeError):
        start_dt_str, end_dt_str = (start_iso.split('T')[0] if start_iso else ""), (end_iso.split('T')[0] if end_iso else "")

    with st.container(border=True):
        st.markdown(f"""
            <div style="font-size:14px; color:#4b5563; line-height:1.8;">
              <span style='font-weight:600;'>í‚¤ì›Œë“œ:</span> {', '.join(kw_main) if kw_main else '(ì—†ìŒ)'}<br>
              <span style='font-weight:600;'>ê¸°ê°„:</span> {start_dt_str} ~ {end_dt_str} (KST)
            </div>
            """, unsafe_allow_html=True)

        csv_path, df_videos = st.session_state.get("last_csv"), st.session_state.get("last_df")
        if csv_path and os.path.exists(csv_path) and df_videos is not None and not df_videos.empty:
            with open(csv_path, "rb") as f: comment_csv_data = f.read()
            buffer = io.BytesIO()
            df_videos.to_csv(buffer, index=False, encoding="utf-8-sig")
            video_csv_data = buffer.getvalue()
            keywords_str = "_".join(kw_main).replace(" ", "_") if kw_main else "data"
            now_str = now_kst().strftime('%Y%m%d')

            col1, col2, col3, col4, _ = st.columns([1.1, 1.2, 1.2, 1.6, 5.0])
            col1.markdown("<div style='font-size:14px; color:#4b...ght:600; padding-top:5px;'>ë‹¤ìš´ë¡œë“œ:</div>", unsafe_allow_html=True)

            with col2:
                st.download_button("ì „ì²´ëŒ“ê¸€", comment_csv_data, f"comments_{keywords_str}_{now_str}.csv", "text/csv")

            with col3:
                st.download_button("ì˜ìƒëª©ë¡", video_csv_data, f"videos_{keywords_str}_{now_str}.csv", "text/csv")

            # âœ… LLMì— ì‹¤ì œë¡œ ë“¤ì–´ê°„ ëŒ“ê¸€ ìƒ˜í”Œ(ê·¸ëŒ€ë¡œ) ë‹¤ìš´ë¡œë“œ
            sample_text = (st.session_state.get("sample_text") or "").strip()
            if sample_text:
                sample_bytes = sample_text.encode("utf-8-sig")
                with col4:
                    st.download_button(
                        "AIìƒ˜í”Œ(LLMì…ë ¥)",
                        sample_bytes,
                        f"llm_sample_{keywords_str}_{now_str}.txt",
                        "text/plain"
                    )

                sample_cnt = st.session_state.get("sample_count")
                sample_chars = st.session_state.get("sample_chars")
                if sample_cnt is not None and sample_chars is not None:
                    st.caption(f"AI ì…ë ¥ ìƒ˜í”Œ: {sample_cnt:,}ì¤„ / {sample_chars:,} chars")

def render_chat():
    for msg in st.session_state.chat:
        with st.chat_message(msg.get("role", "user")):
            content = msg.get("content", "")
            
            # AI ë‹µë³€ì´ê³ , ë‚´ìš©ì´ HTML íƒœê·¸(<div, <style ë“±)ë¥¼ í¬í•¨í•˜ëŠ” ê²½ìš°
            if isinstance(content, str) and msg.get("role") == "assistant" and ("<div" in content or "<style" in content):
                # ìŠ¤íƒ€ì¼ ì •ì˜ (ê°€ë…ì„± í™•ë³´)
                report_style = """
                <style>
                .yt-report { font-family: "Helvetica Neue", Arial, sans-serif; line-height: 1.6; color: #333; }
                .yt-report .header { border-bottom: 2px solid #eee; padding-bottom: 10px; margin-bottom: 15px; }
                .yt-report .badge { background: #f0f2f6; color: #31333F; padding: 2px 8px; border-radius: 4px; font-size: 0.85em; margin-right: 5px; font-weight: 600; }
                .yt-report .card { background: white; border: 1px solid #ddd; border-radius: 8px; padding: 15px; margin-bottom: 15px; box-shadow: 0 1px 3px rgba(0,0,0,0.05); }
                .yt-report h3 { font-size: 1.1em; margin-top: 0; margin-bottom: 10px; color: #000; font-weight: 700; }
                .yt-report .quote { border-left: 3px solid #ff4b4b; padding-left: 10px; color: #555; font-style: italic; margin: 5px 0; font-size: 0.95em; background: #fafafa; padding: 5px 10px; }
                .yt-report table { width: 100%; border-collapse: collapse; font-size: 0.9em; margin: 10px 0; }
                .yt-report th { text-align: left; border-bottom: 2px solid #ddd; padding: 5px; color: #555; background-color: #f9fafb; }
                .yt-report td { border-bottom: 1px solid #eee; padding: 8px 5px; vertical-align: top; }
</style>
                """
                
                # [ì•ˆì „ì¥ì¹˜] ì˜ë¦° íƒœê·¸ ë°©ì§€ë¥¼ ìœ„í•´ divë¡œ ê°ìŒˆ (ë¸Œë¼ìš°ì €ê°€ ì›¬ë§Œí•˜ë©´ ë‹«ì•„ì¤Œ)
                # unsafe_allow_html=Trueë¡œ ë Œë”ë§í•´ì•¼ ì½”ë“œê°€ ì•ˆ ë³´ì´ê³  ë””ìì¸ì´ ì ìš©ë¨
                full_html = f"<div class='yt-report'>{report_style}{content}</div>"
                st.markdown(full_html, unsafe_allow_html=True)
                
            else:
                # ì¼ë°˜ í…ìŠ¤íŠ¸ ëŒ€í™”
                st.markdown(content)


def render_sidebar_controls_html(display_name: str, role: str, show_actions: bool, pdf_basename: str):
    """ì‚¬ì´ë“œë°” ìƒë‹¨ UIë¥¼ Streamlit ìœ„ì ¯ì´ ì•„ë‹ˆë¼ 'ë‹¨ì¼ HTML ë¸”ë¡'ìœ¼ë¡œ ë Œë”ë§í•œë‹¤.

    - Streamlitì€ ë§ˆí¬ë‹¤ìš´ HTMLë¡œ ìœ„ì ¯ì„ ê°ìŒ€ ìˆ˜ ì—†ì–´ì„œ(=CSSê°€ ì•ˆ ë¨¹ìŒ),
      ìƒë‹¨ ì»¨íŠ¸ë¡¤(ë¡œê·¸ì•„ì›ƒ/ìƒˆì±„íŒ…/ì„¸ì…˜ì €ì¥/PDFì €ì¥)ì„ í•˜ë‚˜ì˜ HTMLë¡œ ë¬¶ì–´ ìŠ¤íƒ€ì¼/ê°„ê²©ì„ ì™„ì „ ê³ ì •í•œë‹¤.
    - ìƒˆì±„íŒ…/ì„¸ì…˜ì €ì¥/ë¡œê·¸ì•„ì›ƒì€ query paramìœ¼ë¡œ ì•¡ì…˜ì„ ì „ë‹¬í•´ ì„œë²„ì—ì„œ ì²˜ë¦¬í•œë‹¤.
    - PDFì €ì¥ì€ í´ë¼ì´ì–¸íŠ¸ì—ì„œ ëŒ€í™” DOMì„ ìº¡ì³í•´ PDFë¡œ ì €ì¥í•œë‹¤.
    """

    disp = (display_name or "").strip() or "ì‚¬ìš©ì"
    role = (role or "user").strip() or "user"

    safe_pdf = re.sub(r'[\\/:*?"<>|]+', "_", (pdf_basename or "chat")).strip()
    safe_pdf = re.sub(r"\s+", "_", safe_pdf) or "chat"

    # iframe ë‚´ë¶€ì—ì„œë§Œ ì“°ëŠ” ëœë¤ id
    rid = uuid4().hex[:8]

    tpl = r'''
<div class="ytcc-sb-wrap" id="ytcc_sb__RID__">
  <div class="ytcc-sb-title">ğŸ’¬ ìœ íŠœë¸Œ ëŒ“ê¸€ë¶„ì„: <span>AI ì±—ë´‡</span></div>

  <div class="ytcc-sb-userrow">
    <div class="ytcc-sb-userleft">
      <div class="ytcc-sb-user">ğŸ‘¤ __DISP__ <span class="ytcc-sb-role">(__ROLE__)</span></div>
    </div>
    <div class="ytcc-sb-userright">
      <a href="javascript:void(0)" class="ytcc-sb-logout" id="ytcc_logout__RID__">ë¡œê·¸ì•„ì›ƒ</a>
    </div>
  </div>

  <div class="ytcc-sb-gap"></div>

  <button class="ytcc-btn ytcc-btn-secondary" id="ytcc_newchat__RID__">ìƒˆì±„íŒ…</button>

  __ACTIONS__

</div>

<style>
  /* ì´ ë¸”ë¡(iframe) ì•ˆì—ì„œë§Œ ì ìš©ë˜ëŠ”, ì™„ì „ ë…ë¦½ ìŠ¤íƒ€ì¼ */
  html, body { margin:0; padding:0; background:transparent; font-family:-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,"Noto Sans KR",Arial,sans-serif; }

  .ytcc-sb-wrap{
    width:100%;
    box-sizing:border-box;
  }

  .ytcc-sb-title{
    font-weight:800;
    font-size: 1.55rem;
    line-height: 1.15;
    margin: 0 0 8px 0;
    background: -webkit-linear-gradient(45deg, #4285F4, #9B72CB, #D96570, #F2A60C);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
  }
  .ytcc-sb-title span{ font-weight:800; }

  .ytcc-sb-userrow{
    display:flex;
    align-items:flex-start;
    justify-content:space-between;
    gap: 10px;
    margin: 0;
  }
  .ytcc-sb-user{
    font-size: 0.95rem;
    font-weight: 700;
    color:#111827;
    line-height:1.25;
    margin: 0;
  }
  .ytcc-sb-role{
    font-size: 0.78rem;
    font-weight: 600;
    color:#6b7280;
  }
  .ytcc-sb-logout{
    font-size: 0.78rem;
    color: #6b7280;
    text-decoration: underline;
    font-weight: 600;
    line-height:1.1;
  }
  .ytcc-sb-logout:hover{ color:#374151; }

  .ytcc-sb-gap{ height: 10px; }

  .ytcc-btn{
    width:100%;
    border-radius: 14px;
    padding: 0.55rem 0.65rem;
    font-size: 0.90rem;
    font-weight: 750;
    line-height: 1.1;
    border: 1px solid #e5e7eb;
    background: #ffffff;
    color:#111827;
    cursor:pointer;
    box-sizing:border-box;
  }
  .ytcc-btn:hover{
    background:#f9fafb;
    border-color:#d1d5db;
  }

  .ytcc-btn-secondary{
    background:#e8f0fe;
    border-color:#d2e3fc;
    color:#0052CC;
  }
  .ytcc-btn-secondary:hover{
    background:#d2e3fc;
    border-color:#c2d8f8;
    color:#0041A3;
  }

  .ytcc-row{
    display:flex;
    gap: 10px;
    margin-top: 10px;
  }
  .ytcc-row .ytcc-btn{ width: 50%; }

  .ytcc-btn-success{
    background:#eafaf1;
    border-color:#cdeedb;
    color:#127a3a;
  }
  .ytcc-btn-success:hover{
    background:#d6f3e4;
    border-color:#bfe8d3;
    color:#0f6a32;
  }

  /* iframe ìì²´ ë†’ì´ë¡œ ê³µë°± ìµœì†Œí™” */
  .ytcc-bottom-gap{ height: 4px; }
</style>

<script>
(function(){
  // âœ… Streamlit components iframe ê¹Šì´ì— ìƒê´€ì—†ì´ ìµœìƒìœ„(ê°™ì€ origin) window ì°¾ê¸°
  const P = (function(){
    try{
      let w = window;
      while (w.parent && w.parent !== w) w = w.parent;
      return w;
    }catch(e){
      return window.parent;
    }
  })();
  const DOC = P.document;

  // âœ… í•œ ë²ˆì— query param ì„¸íŒ…/ì‚­ì œ í›„, ê°™ì€ ì°½ì—ì„œ í™•ì‹¤íˆ ë¦¬ë¡œë“œ
  function navigate(setObj, delKeys){
    try{
      const url = new URL(P.location.href);
      const sp = url.searchParams;

      (delKeys || []).forEach(k => { try{ sp.delete(k); }catch(e){} });
      Object.entries(setObj || {}).forEach(([k,v])=>{
        if(v === null || v === undefined || String(v).trim()===""){
          sp.delete(k);
        } else {
          sp.set(k, v);
        }
      });

      url.search = sp.toString();

      // 1) URLë§Œ êµì²´(ë™ì¼ í˜ì´ì§€) â†’ 2) ë¦¬ë¡œë“œ (sandbox/top-nav ì œì•½ íšŒí”¼ì— ìœ ë¦¬)
      try{
        P.history.replaceState(null, "", url.toString());
        P.location.reload();
        return;
      }catch(e){}

      // fallback
      try{ P.location.assign(url.toString()); return; }catch(e){}
      try{ P.location.href = url.toString(); }catch(e){}
    }catch(e){
      console.error(e);
    }
  }

  // ì•¡ì…˜ ë²„íŠ¼ë“¤
  const btnLogout = document.getElementById("ytcc_logout__RID__");
  const btnNew = document.getElementById("ytcc_newchat__RID__");
  const btnSave = document.getElementById("ytcc_save__RID__");
  const btnPdf  = document.getElementById("ytcc_pdf__RID__");

  if(btnLogout){
    btnLogout.addEventListener("click", ()=>{ navigate({logout:"1"}, ["action"]); });
  }
  if(btnNew){
    btnNew.addEventListener("click", ()=>{ navigate({action:"new_chat"}, ["logout"]); });
  }
  if(btnSave){
    btnSave.addEventListener("click", ()=>{ navigate({action:"save_session"}, ["logout"]); });
  }

  // --- PDF ìº¡ì³ (ëŒ€í™”ì°½ë§Œ / ìŠ¤í¬ë¡¤ ëê¹Œì§€) ---
  function ensureScript(src, globalName){
    return new Promise((resolve, reject)=>{
      try{
        if(globalName && P[globalName]) return resolve(true);
        if(DOC.querySelector('script[data-ytcc-src="'+src+'"]')) return resolve(true);
        const s = DOC.createElement("script");
        s.src = src;
        s.async = true;
        s.setAttribute("data-ytcc-src", src);
        s.onload = ()=>resolve(true);
        s.onerror = ()=>reject(new Error("load failed: "+src));
        DOC.head.appendChild(s);
      }catch(e){ reject(e); }
    });
  }

  async function captureToPdf(){
    if(!btnPdf) return;
    const original = btnPdf.innerText;
    btnPdf.disabled = true;
    btnPdf.innerText = "ìº¡ì³ì¤‘...";

    try{
      await ensureScript("https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.4.1/html2canvas.min.js", "html2canvas");
      await ensureScript("https://cdnjs.cloudflare.com/ajax/libs/jspdf/2.5.1/jspdf.umd.min.js", "jspdf");

      const msgs = Array.from(DOC.querySelectorAll('[data-testid="stChatMessage"]'));
      if(!msgs.length){
        alert("ìº¡ì³í•  ëŒ€í™”ê°€ ì—†ìŠµë‹ˆë‹¤.");
        return;
      }

      // ì²« ë©”ì‹œì§€ í­ ê¸°ë°˜ìœ¼ë¡œ ìº¡ì³ ì»¨í…Œì´ë„ˆ í­ í™•ë³´ (ìš°ì¸¡ ì˜ë¦¼ ë°©ì§€)
      const r = msgs[0].getBoundingClientRect();
      let capW = Math.max(1200, Math.min(1700, (r.width || 1200) + 160));

      const tmp = DOC.createElement("div");
      tmp.id = "ytcc_capture_tmp__RID__";
      tmp.style.position = "absolute";
      tmp.style.left = "0px";
      tmp.style.top = "0px";
      tmp.style.transform = "translateX(-24000px)";
      tmp.style.width = capW + "px";
      tmp.style.background = "#ffffff";
      tmp.style.padding = "18px 22px";
      tmp.style.borderRadius = "12px";
      tmp.style.color = "#111827";
      tmp.style.boxSizing = "border-box";
      tmp.style.overflow = "visible";
      tmp.style.overflowWrap = "anywhere";
      tmp.style.wordBreak = "break-word";

      const title = DOC.createElement("div");
      title.style.fontSize = "14px";
      title.style.fontWeight = "800";
      title.style.marginBottom = "6px";
      title.innerText = "ìœ íŠœë¸Œ ëŒ“ê¸€ë¶„ì„: AI ì±—ë´‡ â€” ëŒ€í™” ìº¡ì³";
      tmp.appendChild(title);

      const meta = DOC.createElement("div");
      meta.style.fontSize = "12px";
      meta.style.color = "#6b7280";
      meta.style.marginBottom = "10px";
      meta.innerText = "ìƒì„±ì¼ì‹œ: " + (new Date()).toLocaleString();
      tmp.appendChild(meta);

      msgs.forEach(m => tmp.appendChild(m.cloneNode(true)));
      DOC.body.appendChild(tmp);

      // í•˜ìœ„ ìš”ì†Œ í­/ì¤„ë°”ê¿ˆ ê°•ì œ
      tmp.querySelectorAll("*").forEach(el => {
        el.style.boxSizing = "border-box";
        el.style.maxWidth = "100%";
        el.style.overflowWrap = "anywhere";
        el.style.wordBreak = "break-word";
      });

      const canvas = await P.html2canvas(tmp, {
        scale: 2,
        useCORS: true,
        backgroundColor: "#ffffff",
        logging: false,
        windowWidth: capW,
      });

      DOC.body.removeChild(tmp);

      const imgData = canvas.toDataURL("image/png");
      const { jsPDF } = P.jspdf;

      const pdf = new jsPDF("p", "pt", "a4");
      const pageWidth = pdf.internal.pageSize.getWidth();
      const pageHeight = pdf.internal.pageSize.getHeight();

      const imgWidth = pageWidth;
      const imgHeight = (canvas.height * imgWidth) / canvas.width;

      let heightLeft = imgHeight;
      let position = 0;

      pdf.addImage(imgData, "PNG", 0, position, imgWidth, imgHeight);
      heightLeft -= pageHeight;

      while (heightLeft > 0) {
        position = heightLeft - imgHeight;
        pdf.addPage();
        pdf.addImage(imgData, "PNG", 0, position, imgWidth, imgHeight);
        heightLeft -= pageHeight;
      }

      pdf.save("__PDFNAME__.pdf");
    }catch(err){
      console.error(err);
      alert("PDF ìº¡ì³ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì½˜ì†” ë¡œê·¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.");
    }finally{
      btnPdf.disabled = false;
      btnPdf.innerText = original;
    }
  }

  if(btnPdf){
    btnPdf.addEventListener("click", captureToPdf);
  }
})();
</script>
'''

    actions_html = ""
    if show_actions:
        actions_html = r'''
  <div class="ytcc-row">
    <button class="ytcc-btn ytcc-btn-success" id="ytcc_save__RID__">ì„¸ì…˜ì €ì¥</button>
    <button class="ytcc-btn ytcc-btn-success" id="ytcc_pdf__RID__">PDFì €ì¥</button>
  </div>
  <div class="ytcc-bottom-gap"></div>
'''
    else:
        actions_html = '<div class="ytcc-bottom-gap"></div>'

    html_str = (tpl
        .replace("__RID__", rid)
        .replace("__DISP__", disp.replace("&","&amp;").replace("<","&lt;").replace(">","&gt;"))
        .replace("__ROLE__", role.replace("&","&amp;").replace("<","&lt;").replace(">","&gt;"))
        .replace("__ACTIONS__", actions_html.replace("__RID__", rid))
        .replace("__PDFNAME__", safe_pdf)
    )

    st_html(html_str, height=210 if show_actions else 170)

# endregion

# region [Main Pipeline]

LIGHT_PROMPT = (
    "ì—­í• : ìœ íŠœë¸Œ ëŒ“ê¸€ ë°˜ì‘ ë¶„ì„ê¸°ì˜ ìì—°ì–´ í•´ì„ê°€.\n"
    "ëª©í‘œ: í•œêµ­ì–´ ì…ë ¥ì—ì„œ [ê¸°ê°„(KST)]ê³¼ [í‚¤ì›Œë“œ/ì˜µì…˜]ë§Œ ì •í™•íˆ ì¶”ì¶œ.\n"
    "ê·œì¹™:\n"
    "- ê¸°ê°„ì€ Asia/Seoul ê¸°ì¤€, ìƒëŒ€ê¸°ê°„ì˜ ì¢…ë£ŒëŠ” ì§€ê¸ˆ.\n"
    "- 'í‚¤ì›Œë“œ'ëŠ” ê²€ìƒ‰ì— ì‚¬ìš©í•  í•µì‹¬ ì£¼ì œ 1ê°œë¡œ í•œì •.\n"
    "- ì˜µì…˜: include_replies, channel_filter(any|official|unofficial), lang(ko|en|auto).\n\n"
    "ì¶œë ¥(5ì¤„ ê³ ì •):\n"
    "- í•œ ì¤„ ìš”ì•½: <ë¬¸ì¥>\n"
    "- ê¸°ê°„(KST): <YYYY-MM-DDTHH:MM:SS+09:00> ~ <YYYY-MM-DDTHH:MM:SS+09:00>\n"
    "- í‚¤ì›Œë“œ: [<í•µì‹¬ í‚¤ì›Œë“œ 1ê°œ>]\n"
    "- ì˜µì…˜: { include_replies: true|false, channel_filter: \"any|official|unofficial\", lang: \"ko|en|auto\" }\n"
    "- ì›ë¬¸: {USER_QUERY}\n\n"
    f"í˜„ì¬ KST: {to_iso_kst(now_kst())}\n"
    "ì…ë ¥:\n{USER_QUERY}"
)

def parse_light_block_to_schema(light_text: str) -> dict:
    """LIGHT_PROMPT ê²°ê³¼(5ì¤„)ë¥¼ schemaë¡œ íŒŒì‹±."""
    raw = (light_text or "").strip()

    m_time = re.search(r"ê¸°ê°„\(KST\)\s*:\s*([^~]+)~\s*([^\n]+)", raw)
    start_iso, end_iso = (m_time.group(1).strip(), m_time.group(2).strip()) if m_time else (None, None)

    m_kw = re.search(r"í‚¤ì›Œë“œ\s*:\s*\[(.*?)\]", raw, flags=re.DOTALL)
    keywords = [p.strip() for p in re.split(r"\s*,\s*", m_kw.group(1)) if p.strip()] if m_kw else []

    m_opt = re.search(r"ì˜µì…˜\s*:\s*\{(.*?)\}", raw, flags=re.DOTALL)
    options = {"include_replies": False, "channel_filter": "any", "lang": "auto"}
    if m_opt:
        blob = m_opt.group(1)
        ir = re.search(r"include_replies\s*:\s*(true|false)", blob, re.I)
        if ir:
            options["include_replies"] = (ir.group(1).lower() == "true")
        cf = re.search(r"channel_filter\s*:\s*\"(any|official|unofficial)\"", blob, re.I)
        if cf:
            options["channel_filter"] = cf.group(1)
        lg = re.search(r"lang\s*:\s*\"(ko|en|auto)\"", blob, re.I)
        if lg:
            options["lang"] = lg.group(1)

    if not (start_iso and end_iso):
        end_dt = now_kst()
        start_dt = end_dt - timedelta(hours=24)
        start_iso, end_iso = to_iso_kst(start_dt), to_iso_kst(end_dt)

    if not keywords:
        tokens = re.findall(r"[ê°€-í£A-Za-z0-9]{2,}", raw)
        keywords = [tokens[0]] if tokens else ["ìœ íŠœë¸Œ"]

    return {"start_iso": start_iso, "end_iso": end_iso, "keywords": keywords, "options": options, "raw": raw}


def run_pipeline_first_turn(user_query: str, extra_video_ids=None, only_these_videos: bool = False):
    extra_video_ids = list(dict.fromkeys(extra_video_ids or []))
    prog_bar = st.progress(0, text="ì¤€ë¹„ ì¤‘â€¦")

    if not GEMINI_API_KEYS: return "ì˜¤ë¥˜: Gemini API Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    prog_bar.progress(0.05, text="í•´ì„ì¤‘â€¦")
    
    light = call_gemini_rotating(GEMINI_MODEL, GEMINI_API_KEYS, "", LIGHT_PROMPT.replace("{USER_QUERY}", user_query))
    schema = parse_light_block_to_schema(light)
    st.session_state["last_schema"] = schema

    prog_bar.progress(0.10, text="ì˜ìƒ ìˆ˜ì§‘ì¤‘â€¦")
    if not YT_API_KEYS: return "ì˜¤ë¥˜: YouTube API Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    
    rt = RotatingYouTube(YT_API_KEYS)
    start_dt, end_dt = datetime.fromisoformat(schema["start_iso"]), datetime.fromisoformat(schema["end_iso"])
    kw_main = schema.get("keywords", [])

    own_mode = bool(st.session_state.get("own_ip_mode", False))
    pgc_ids = []
    
    # [ìˆ˜ì •] ìì‚¬ IP ëª¨ë“œ ì²˜ë¦¬
    if own_mode:
        cache_dir = _cache_local_dir()
        cache_files = [fn for fn in os.listdir(cache_dir) if re.fullmatch(r"cache_token_.*\.json", fn)]
        if not cache_files:
            return f"ìì‚¬ëª¨ë“œ ìºì‹œ íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {os.path.join(cache_dir, 'cache_token_*.json')}"
        
        for base_kw in (kw_main or []):
            # [í•µì‹¬] í‚¤ì›Œë“œì™€ í•¨ê»˜ start_dt, end_dtë¥¼ ë„˜ê²¨ ê¸°ê°„ í•„í„°ë§ ì ìš©
            pgc_ids.extend(load_pgc_video_ids_by_keyword(base_kw, start_dt, end_dt))
        pgc_ids = list(dict.fromkeys(pgc_ids))

    if only_these_videos and extra_video_ids:
        all_ids = extra_video_ids
    else:
        all_ids = []
        # UGC ê²€ìƒ‰
        for base_kw in (kw_main or ["ìœ íŠœë¸Œ"]):
            search_kw = hashtagify_keyword(base_kw)
            if search_kw:
                all_ids.extend(yt_search_videos(rt, search_kw, 60, "viewCount", kst_to_rfc3339_utc(start_dt), kst_to_rfc3339_utc(end_dt)))
        
        if extra_video_ids:
            all_ids.extend(extra_video_ids)
            
        # PGC ì•„ì´ë”” í•©ì¹˜ê¸°
        if own_mode and pgc_ids:
            all_ids.extend(pgc_ids)

    all_ids = list(dict.fromkeys(all_ids))
    prog_bar.progress(0.40, text="ëŒ“ê¸€ ìˆ˜ì§‘ ì¤€ë¹„ì¤‘â€¦")

    df_stats = pd.DataFrame(yt_video_statistics(rt, all_ids))
    
    if bool(st.session_state.get("own_ip_mode", False)) and (not df_stats.empty) and ("title" in df_stats.columns):
        df_stats = df_stats[~df_stats["title"].astype(str).str.contains(r"\bOST\b", case=False, na=False)]
    
    st.session_state["last_df"] = df_stats

    csv_path, total_cnt = parallel_collect_comments_streaming(
        df_stats.to_dict('records'), YT_API_KEYS, bool(schema.get("options", {}).get("include_replies")),
        MAX_TOTAL_COMMENTS, MAX_COMMENTS_PER_VID, prog_bar
    )
    st.session_state["last_csv"] = csv_path

    if total_cnt == 0:
        prog_bar.empty()
        return "ì§€ì • ì¡°ê±´ì—ì„œ ëŒ“ê¸€ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì¡°ê±´ìœ¼ë¡œ ì‹œë„í•´ ë³´ì„¸ìš”."

    prog_bar.progress(0.90, text="AI ë¶„ì„ì¤‘â€¦")

    sample_text, sample_cnt, sample_chars, sample_meta = serialize_comments_for_llm_from_file(csv_path)

    st.session_state["sample_text"] = sample_text
    st.session_state["sample_count"] = sample_cnt
    st.session_state["sample_chars"] = sample_chars
    st.session_state["sample_meta"] = sample_meta

    sys = load_first_turn_system_prompt()

    used_top = sample_meta.get("used_top", 0)
    used_random = sample_meta.get("used_random", 0)
    max_per = sample_meta.get("max_chars_per_comment", 0)
    max_total = sample_meta.get("max_total_chars", 0)

    analysis_scope_line = (
        f"{sample_cnt:,}ê°œ (ì¶”ì¶œ: ì¸ê¸°ëŒ“ê¸€ {used_top:,}ê°œ + ëœë¤ {used_random:,}ê°œ, "
        f"ëŒ“ê¸€ë‹¹ {max_per}ì ì»·, ì´ {max_total:,}ì ì»·)"
    )
    st.session_state["analysis_scope_line"] = analysis_scope_line

    metrics_block = (
        "[METRICS]\n"
        f"TOTAL_COLLECTED_COMMENTS={sample_meta.get('total_rows', 'NA')}\n"
        f"UNIQUE_COMMENTS_BY_{str(sample_meta.get('dedup_key','text')).upper()}={sample_meta.get('unique_rows', 'NA')}\n"
        f"SAMPLE_RULE=top_like:{used_top}/{sample_meta.get('top_n', 1000)}, random:{used_random}/{sample_meta.get('random_n', 1000)}\n"
        f"LLM_INPUT_LINES={sample_cnt}\n"
        f"LLM_INPUT_CHARS={sample_chars}\n"
        f"ANALYSIS_COMMENT_COUNT_LINE={analysis_scope_line}\n"
    )

    # [í•µì‹¬] ìŠ¤ë§ˆíŠ¸ ìºì‹±ì„ ìœ„í•œ Context êµ¬ì„± (ëŒ€ìš©ëŸ‰ ë°ì´í„°)
    large_context_text = (
        f"{metrics_block}\n"
        f"[í‚¤ì›Œë“œ]: {', '.join(kw_main)}\n"
        f"[ê¸°ê°„(KST)]: {schema['start_iso']} ~ {schema['end_iso']}\n\n"
        f"[ëŒ“ê¸€ ìƒ˜í”Œ]:\n{sample_text}\n"
    )
    user_query_part = f"[ì‚¬ìš©ì ì›ë³¸ ì§ˆë¬¸]: {user_query}"

    # ìºì‹œ ì´ˆê¸°í™” (ìƒˆ ì§ˆë¬¸ì´ë¯€ë¡œ)
    if "current_cache" in st.session_state:
        del st.session_state["current_cache"]

    # [ìˆ˜ì •] call_gemini_smart_cache ì‚¬ìš© (ê¸°ì¡´ ê¸°ëŠ¥ ìœ ì§€)
    answer_md_raw = call_gemini_smart_cache(
        GEMINI_MODEL, GEMINI_API_KEYS, sys, user_query_part,
        large_context_text=large_context_text,
        cache_key_in_session="current_cache"
    )

    prog_bar.progress(1.0, text="ì™„ë£Œ")
    time.sleep(0.5)
    prog_bar.empty()
    gc.collect()

    return tidy_answer(answer_md_raw)


# [ë³µêµ¬] Smart Cacheë¥¼ í™œìš©í•˜ëŠ” run_followup_turn
def run_followup_turn(user_query: str):
    if not (schema := st.session_state.get("last_schema")):
        return "ì˜¤ë¥˜: ì´ì „ ë¶„ì„ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤. ìƒˆ ì±„íŒ…ì„ ì‹œì‘í•´ì£¼ì„¸ìš”."

    context = "\n".join(f"[ì´ì „ {'Q' if m['role'] == 'user' else 'A'}]: {m['content']}" for m in st.session_state["chat"][-10:])

    followup_instruction = (
        "ğŸ›‘ [ì§€ì‹œì‚¬í•­ ë³€ê²½] ğŸ›‘\n"
        "ì§€ê¸ˆë¶€í„°ëŠ” ì „ì²´ ìš”ì•½ê°€ê°€ ì•„ë‹ˆë¼, ì‚¬ìš©ìì˜ ì§ˆë¬¸ í•˜ë‚˜í•˜ë‚˜ë¥¼ íŒŒê³ ë“œëŠ” **'ì‹¬ì¸µ ë¶„ì„ê°€'**ë¡œì„œ í–‰ë™í•´.\n"
        "ì´ì „ì˜ ìš”ì•½ ë¯¸ì…˜ì€ ìŠì–´. ì˜¤ì§ ì•„ë˜ [í˜„ì¬ ì§ˆë¬¸]ì—ë§Œ ì§‘ì¤‘í•´ì„œ ë‹µí•´.\n\n"
        "=== ë‹µë³€ ì „ëµ ===\n"
        "1. ì§ˆë¬¸ì˜ ì˜ë„(ì†ì„±/ëŒ€ìƒ)ë¥¼ ë¨¼ì € íŒŒì•…í•´ë¼.\n"
        "2. ë„¤ ê¸°ì–µ ì†ì— ìˆëŠ” [ëŒ“ê¸€ ìƒ˜í”Œ]ì—ì„œ ê·¸ì™€ ê´€ë ¨ëœ êµ¬ì²´ì ì¸ ì¦ê±°(ëŒ“ê¸€)ë¥¼ ì°¾ì•„ë¼.\n"
        "3. ë­‰ëš±ê·¸ë ¤ ë§í•˜ì§€ ë§ê³ , `> ëŒ“ê¸€ ë‚´ìš©` í˜•ì‹ìœ¼ë¡œ ì§ì ‘ ì¸ìš©í•˜ë©° ê·¼ê±°ë¥¼ ëŒ€ë¼.\n"
        "4. ì§ˆë¬¸ê³¼ ê´€ë ¨ ì—†ëŠ” TMI(ë‹¤ë¥¸ ë°°ìš°, ë‹¤ë¥¸ ì´ìŠˆ ë“±)ëŠ” ì ˆëŒ€ ë§í•˜ì§€ ë§ˆë¼.\n"
        "5. ë§Œì•½ ê´€ë ¨ ë‚´ìš©ì´ ë°ì´í„°ì— ì—†ìœ¼ë©´ 'ë°ì´í„°ì—ì„œ í™•ì¸ë˜ì§€ ì•ŠëŠ”ë‹¤'ê³  ë”± ì˜ë¼ ë§í•´ë¼.\n"
    )

    user_payload = (
        f"{followup_instruction}\n\n"
        f"{context}\n\n"
        f"[í˜„ì¬ ì§ˆë¬¸]: {user_query}\n"
        f"[ê¸°ê°„(KST)]: {schema.get('start_iso', '?')} ~ {schema.get('end_iso', '?')}\n"
    )

    with st.spinner("ğŸ’¬ ì‹¬ì¸µ ë¶„ì„ ì¤‘... (Smart Cache)"):
        # call_gemini_smart_cache í˜¸ì¶œ (large_context_text=None -> ê¸°ì¡´ ìºì‹œ ì‚¬ìš©)
        response_raw = call_gemini_smart_cache(GEMINI_MODEL, GEMINI_API_KEYS, "", user_payload, large_context_text=None)
        response = tidy_answer(response_raw)

    return response
# endregion


# region [Main Execution]
require_auth()

# --- Sidebar actions (HTML controls -> query params) ---
_qp = _qp_get()

def _qp_first(val):
    if val is None:
        return None
    if isinstance(val, (list, tuple)):
        return val[0] if val else None
    return val

_auth_tok = _qp_first(_qp.get("auth"))
_action = _qp_first(_qp.get("action"))

if _action == "new_chat":
    _reset_chat_only(keep_auth=True)
    _qp_set(auth=_auth_tok)  # keep auth only
    st.rerun()

if _action == "save_session":
    if st.session_state.get("chat") and st.session_state.get("last_csv"):
        with st.spinner("ì„¸ì…˜ ì €ì¥ ì¤‘..."):
            ok, result = save_current_session_to_github()
        if ok:
            st.session_state["_toast_msg"] = {"text": f"'{result}' ì €ì¥ ì™„ë£Œ!", "icon": "âœ…"}
        else:
            st.session_state["_toast_msg"] = {"text": str(result), "icon": "âš ï¸"}
    _qp_set(auth=_auth_tok)  # keep auth only (and clear action)
    st.rerun()

with st.sidebar:
    disp = st.session_state.get("auth_display_name", st.session_state.get("auth_user_id") or "ì‚¬ìš©ì")
    role = st.session_state.get("auth_role", "user")

    show_actions = bool(st.session_state.get("chat") and st.session_state.get("last_csv"))
    pdf_title = _session_title_for_pdf()
    render_sidebar_controls_html(disp, role, show_actions, pdf_title)

    # one-time toast (ë ˆì´ì•„ì›ƒ ê¹¨ì§€ì§€ ì•Šê²Œ overlay ìš°ì„ )
    _t = st.session_state.pop("_toast_msg", None)
    if _t and isinstance(_t, dict):
        try:
            st.toast(_t.get("text", ""), icon=_t.get("icon", ""))
        except Exception:
            st.caption(_t.get("text", ""))

    st.markdown("---")
    st.markdown("#### ëŒ€í™” ê¸°ë¡")

    if not all([GITHUB_TOKEN, GITHUB_REPO]):
        st.caption("GitHub ì„¤ì •ì´ Secretsì— ì—†ìŠµë‹ˆë‹¤.")
    else:
        try:
            user_id = st.session_state.get("auth_user_id") or "public"
            sessions = sorted(github_list_dir(GITHUB_REPO, GITHUB_BRANCH, f"sessions/{user_id}", GITHUB_TOKEN), reverse=True)
            if not sessions: st.caption("ì €ì¥ëœ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
            else:
                editing_session = st.session_state.get("editing_session", None)
                st.markdown('<div class="session-list">', unsafe_allow_html=True)
                for sess in sessions:
                    if sess == editing_session:
                        new_name = st.text_input("ìƒˆ ì´ë¦„:", value=sess, key=f"new_name_{sess}")
                        c1, c2 = st.columns(2)
                        if c1.button("âœ…", key=f"save_{sess}"):
                            st.session_state.session_to_rename = (sess, new_name)
                            st.session_state.pop('editing_session', None)
                            st.rerun()
                        if c2.button("âŒ", key=f"cancel_{sess}"):
                            st.session_state.pop('editing_session', None)
                            st.rerun()
                    else:
                        c1, c2 = st.columns([0.84, 0.16], gap="small")
                        with c1:
                            st.markdown('<div class="sess-name">', unsafe_allow_html=True)
                            if st.button(sess, key=f"sess_{sess}", use_container_width=True):
                                st.session_state.session_to_load = sess
                                st.rerun()
                            st.markdown('</div>', unsafe_allow_html=True)
                        with c2:
                            st.markdown('<div class="more-menu">', unsafe_allow_html=True)
                            if hasattr(st, "popover"):
                                with st.popover("â‹¯"):
                                    if st.button("ì´ë¦„ ë³€ê²½", key=f"more_edit_{sess}", use_container_width=True):
                                        st.session_state.editing_session = sess
                                        st.rerun()
                                    if st.button("ì‚­ì œ", key=f"more_del_{sess}", use_container_width=True):
                                        st.session_state.session_to_delete = sess
                                        st.rerun()
                            else:
                                with st.expander("â‹¯"):
                                    if st.button("ì´ë¦„ ë³€ê²½", key=f"more_edit_{sess}", use_container_width=True):
                                        st.session_state.editing_session = sess
                                        st.rerun()
                                    if st.button("ì‚­ì œ", key=f"more_del_{sess}", use_container_width=True):
                                        st.session_state.session_to_delete = sess
                                        st.rerun()
                            st.markdown('</div>', unsafe_allow_html=True)
                st.markdown('</div>', unsafe_allow_html=True)
        except Exception: st.error("ê¸°ë¡ ë¡œë”© ì‹¤íŒ¨")
    st.markdown('</div>', unsafe_allow_html=True)

    st.markdown('<div class="sidebar-bottom-section">', unsafe_allow_html=True)
    st.markdown("""<hr><h3>ğŸ“ ë¬¸ì˜</h3><p>ë¯¸ë””ì–´)ë””ì§€í„¸ë§ˆì¼€íŒ… ë°ì´í„°íŒŒíŠ¸</p>""", unsafe_allow_html=True)
    st.markdown('</div>', unsafe_allow_html=True)

# [UI ë¶„ê¸°]
if not st.session_state.chat:
    # 1. ë©”ì¸ í™”ë©´ (ì±„íŒ… ì „): ì—¬ê¸°ì—ë§Œ í† ê¸€ì´ ì¡´ì¬í•´ì•¼ í•¨
    st.markdown(
        """
<div style="display:flex; flex-direction:column; align-items:center; justify-content:center;
            text-align:center; height:70vh;">
  <h1 style="font-size:3.5rem; font-weight:600;
             background:-webkit-linear-gradient(45deg, #4285F4, #9B72CB, #D96570, #F2A60C);
             -webkit-background-clip:text; -webkit-text-fill-color:transparent;">
    ìœ íŠœë¸Œ ëŒ“ê¸€ë¶„ì„: AI ì±—ë´‡
  </h1>
  <p style="font-size:1.2rem; color:#4b5563;">ê´€ë ¨ì˜ìƒ ìœ íŠœë¸Œ ëŒ“ê¸€ë°˜ì‘ì„ AIê°€ ìš”ì•½í•´ì¤ë‹ˆë‹¤</p>
  <div style="margin-top:3rem; padding:1rem 1.5rem; border:1px solid #e5e7eb; border-radius:12px;
              background-color:#fafafa; max-width:600px; text-align:left;">
    <h4 style="margin-bottom:1rem; font-weight:600;">âš ï¸ ì‚¬ìš© ì£¼ì˜ì‚¬í•­</h4>
    <ol style="padding-left:20px;">
      <li><strong>ì²« ì§ˆë¬¸ ì‹œ</strong> ëŒ“ê¸€ ìˆ˜ì§‘ ë° AI ë¶„ì„ì— ì‹œê°„ì´ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</li>
      <li>í•œ ì„¸ì…˜ì—ì„œëŠ” <strong>í•˜ë‚˜ì˜ ì£¼ì œ</strong>ë§Œ ì§„í–‰í•´ì•¼ ë¶„ì„ ì •í™•ë„ê°€ ìœ ì§€ë©ë‹ˆë‹¤.</li>
      <li>ì²« ì§ˆë¬¸ì—ëŠ” <strong>ê¸°ê°„ì„ ëª…ì‹œ</strong>í•´ì£¼ì„¸ìš” (ì˜ˆ: ìµœê·¼ 48ì‹œê°„ / 5ì›” 1ì¼ë¶€í„°).</li>
    </ol>
  </div>
</div>
""", unsafe_allow_html=True)

    # [í† ê¸€ ë²„íŠ¼] ì£¼ì˜ì‚¬í•­ ë°•ìŠ¤ ë°”ë¡œ ì•„ë˜ & ê°€ìš´ë° ì •ë ¬
    _, col_toggle, _ = st.columns([1.3, 1, 1.3])
    with col_toggle:
        st.write("") # ìƒë‹¨ ì—¬ë°±
        st.toggle(
            "ğŸ§© ìì‚¬ IP ëª¨ë“œ",
            key="own_ip_mode",
            help="ON: ìì‚¬(PGC) ìºì‹œë¡œ ê³µì‹ ì˜ìƒ í›„ë³´ë¥¼ í™•ë³´í•˜ê³ , ë™ì‹œì— YouTube ê²€ìƒ‰ìœ¼ë¡œ ì™¸ë¶€(UGC)ê¹Œì§€ í•¨ê»˜ ìˆ˜ì§‘í•©ë‹ˆë‹¤."
        )

        # [ìì‚¬ëª¨ë“œ ìºì‹œ ì²´í¬] (ì›ê²© ë™ê¸°í™” ì—†ìŒ: ë ˆí¬ì˜ pgc_cache/ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©)
        cur_toggle = bool(st.session_state.get("own_ip_mode", False))
        prev_toggle = st.session_state.get("own_ip_toggle_prev", None)

        if cur_toggle and (prev_toggle is None or prev_toggle is False):
            cache_dir = _cache_local_dir()
            cache_files = [fn for fn in os.listdir(cache_dir) if re.fullmatch(r"cache_token_.*\.json", fn)]
            if cache_files:
                st.success(f"ìì‚¬(PGC) ìºì‹œ ì¤€ë¹„ë¨ ({len(cache_files)}ê°œ íŒŒì¼).")
            else:
                st.error(f"ìì‚¬(PGC) ìºì‹œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {os.path.join(cache_dir, 'cache_token_*.json')}")

        st.session_state["own_ip_toggle_prev"] = cur_toggle

else:
    render_metadata_and_downloads()
    render_chat()
    scroll_to_bottom()


if prompt := st.chat_input("ì˜ˆ) ìµœê·¼ 24ì‹œê°„ íƒœí’ìƒì‚¬ ë°˜ì‘ ìš”ì•½í•´ì¤˜ / ë˜ëŠ” ì˜ìƒ URL ë¶™ì—¬ë„ OK"):
    st.session_state.chat.append({"role": "user", "content": prompt})
    st.rerun()

if st.session_state.chat and st.session_state.chat[-1]["role"] == "user":
    user_query = st.session_state.chat[-1]["content"]
    url_ids = extract_video_ids_from_text(user_query)
    natural_text = strip_urls(user_query)
    has_urls = len(url_ids) > 0
    has_natural = len(natural_text) > 0

    if not st.session_state.get("last_csv"):
        if has_urls and not has_natural:
            response = run_pipeline_first_turn(user_query, extra_video_ids=url_ids, only_these_videos=True)
        elif has_urls and has_natural:
            response = run_pipeline_first_turn(user_query, extra_video_ids=url_ids, only_these_videos=False)
        else:
            response = run_pipeline_first_turn(user_query)
    else:
        response = run_followup_turn(user_query)

    st.session_state.chat.append({"role": "assistant", "content": response})
    st.rerun()
# endregion